[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "x + 1"
  },
  {
    "objectID": "drafts/cookbooks/20221105-chloropleth_maps_altair.html",
    "href": "drafts/cookbooks/20221105-chloropleth_maps_altair.html",
    "title": "Plotting Chloropleth Maps Using Altait",
    "section": "",
    "text": "import pandas as pd\nimport altair as alt\nimport vega_datasets as vd\nimport lrdataio"
  },
  {
    "objectID": "drafts/cookbooks/20221105-chloropleth_maps_altair.html#usa-maps",
    "href": "drafts/cookbooks/20221105-chloropleth_maps_altair.html#usa-maps",
    "title": "Plotting Chloropleth Maps Using Altait",
    "section": "USA maps",
    "text": "USA maps\nData: #tidytuesday | American Community Survey | source\nWe will plot the total population at county and state-levels. We will then show how to handle missing data.\nLoad and select the data.\n\ntemp_path = lrdataio.cache_url(('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-04-30/week5_acs2015_county_data.csv'))  # noqa\ntotal_pop_df = pd.read_csv(temp_path, usecols=[0, 1, 2, 3])  # noqa\ntotal_pop_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3220 entries, 0 to 3219\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   CensusId  3220 non-null   int64 \n 1   State     3220 non-null   object\n 2   County    3220 non-null   object\n 3   TotalPop  3220 non-null   int64 \ndtypes: int64(2), object(2)\nmemory usage: 100.8+ KB\n\n\n\ntotal_pop_df.head(3)\n\n\n\n\n\n  \n    \n      \n      CensusId\n      State\n      County\n      TotalPop\n    \n  \n  \n    \n      0\n      1001\n      Alabama\n      Autauga\n      55221\n    \n    \n      1\n      1003\n      Alabama\n      Baldwin\n      195121\n    \n    \n      2\n      1005\n      Alabama\n      Barbour\n      26932\n    \n  \n\n\n\n\n\ntotal_pop_df.tail(3)\n\n\n\n\n\n  \n    \n      \n      CensusId\n      State\n      County\n      TotalPop\n    \n  \n  \n    \n      3217\n      72149\n      Puerto Rico\n      Villalba\n      24685\n    \n    \n      3218\n      72151\n      Puerto Rico\n      Yabucoa\n      36279\n    \n    \n      3219\n      72153\n      Puerto Rico\n      Yauco\n      39474\n    \n  \n\n\n\n\n\nCounties\n\n# loads the fips data\nfips = lrdataio.cache_url('https://raw.githubusercontent.com/kjhealy/fips-codes/master/county_fips_master.csv')  # noqa\nfips_df = pd.read_csv(fips, encoding='cp1252')\n\n\n# load counties geojson\ncounties = alt.topo_feature(vd.data.us_10m.url, 'counties')\n\nalt.Chart(counties).mark_geoshape(\n    stroke='black'\n).encode(\n    color='log(TotalPop):Q'\n).transform_lookup(\n    lookup='id',\n    from_=alt.LookupData(total_pop_df, 'CensusId', ['State',\n                                                    'County',\n                                                    'TotalPop'])\n).project(\n    type='albersUsa'\n)\n\n\n\n\n\n\n\n\n\nStates\n\n\nLoad the data\n\nacs = pl.DataFrame(pd.read_csv(ACS_URL, encoding='latin-1')).lazy()\nacs.schema\n\nNameError: name 'pl' is not defined\n\n\n\n\nPrepare the data\n\n\nSelect columns of interest and standardise.\nstd_acs = acs.select(\n    [(pl.col('Women') / pl.col('TotalPop')).alias('PropWomen'),\n     pl.col('Poverty'),\n     pl.col('PublicWork'),\n     pl.col('IncomePerCap')]\n).select(\n    pl.all().map(standardise)\n)\nprint(std_acs.collect().describe())\n\n\n\n\nVisual 1\n\n\nQuery the data and plot the result\n_g = sns.catplot(\n    data=std_acs.melt().collect().to_pandas(),\n    x='value',\n    y='variable',\n    kind='box',\n    aspect=2\n)\nplt.title('Multiple boxplots of selected standardised variables')\nplt.show()\n\n\n\n\nVisual 2\nPlot a matrix scatterplot of the sampled data.\n\n\nQuery the data and plot the result\n_g = sns.pairplot(\n    data=std_acs.collect().to_pandas(),\n    diag_kws={'bins': 20},\n    height=2,\n)\n_g.fig.suptitle(\n    'Matrix scatterplot of the selected standardised variables',\n    y=1.04\n)\nplt.show()\n\n\n\n\nVisual 3\n\n\nQuery the data and plot the result\n_q1 = std_acs.collect(\n).to_pandas(\n).corr(\n).rename_axis(\n    'X1',\n    axis='index'\n).rename_axis(\n    'X2',\n    axis='columns'\n).round(2)\n\n_g = sns.heatmap(data=_q1, annot=True, vmin=-1, vmax=1, cmap='bwr')\nplt.title('Covariance heatmap')\nplt.show()"
  },
  {
    "objectID": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html",
    "href": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html",
    "title": "LaughingRook",
    "section": "",
    "text": "The aim of this notebook is to take the raw data from the incarceration trends TidyTuesday project, and output a duckdb version of it."
  },
  {
    "objectID": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html#load_frame",
    "href": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html#load_frame",
    "title": "LaughingRook",
    "section": "load_frame()",
    "text": "load_frame()\n\ndef load_frame():\n    source_url = 'https://raw.githubusercontent.com/vera-institute/incarceration-trends/master/incarceration_trends.csv'  # noqa\n    fips_url = 'https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/fips/fips_table.csv'  # noqa\n    left_df = pd.read_csv(lrdataio.cache_url(source_url))\n    right_df = pd.read_csv(lrdataio.cache_url(fips_url), encoding='cp1252')\n    return (\n        left_df\n        .merge(\n            right=right_df[['county_id', 'region_name', 'division_name']],\n            left_on='fips',\n            right_on='county_id',\n        )\n        .drop(columns=['yfips', 'county_id'])\n    )\n\n\nsource_df = load_frame()\nsource_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 153811 entries, 0 to 153810\nColumns: 122 entries, year to division_name\ndtypes: float64(109), int64(6), object(7)\nmemory usage: 144.3+ MB"
  },
  {
    "objectID": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html#visualisations",
    "href": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html#visualisations",
    "title": "LaughingRook",
    "section": "Visualisations",
    "text": "Visualisations\n\nHow has the prison population changed over time?\n\nq = (\n    source_df\n    .query('1984 <= year <= 2016')\n    .groupby('year')[['total_prison_pop', 'total_pop']].sum()\n    .assign(prop=lambda x: x['total_prison_pop'] / x['total_pop'])\n    #.reset_index()\n    #.melt(id_vars='year')\n)\n\n\n(\n    so.Plot(q, x='year', y='prop')\n    .add(so.Line())\n    .theme({**style.library[\"fivethirtyeight\"]})\n)"
  },
  {
    "objectID": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html#schemas",
    "href": "drafts/tidytuesday/20221105-incarceration_trends_to_duckdb.html#schemas",
    "title": "LaughingRook",
    "section": "Schemas",
    "text": "Schemas\n\nsource_df\n\nsource_df.dtypes\n\nyear                        int64\nfips                        int64\nstate                      object\ncounty_name                object\ntotal_pop                   int64\n                           ...   \nlatinx_prison_adm_rate    float64\nnative_prison_adm_rate    float64\nwhite_prison_adm_rate     float64\nregion_name                object\ndivision_name              object\nLength: 122, dtype: object"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Modified - Oldest\n        \n         \n          Modified - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nAdvent of Code 2015\n\n\n\nJuliaLang\n\n\nAdventOfCode\n\n\n\n\nNov 12, 2022\n\n\n\n\n\n11/12/22, 11:41:18 AM\n\n\n\n\n\n\n\n\n\n\nZ-Tests\n\n\n\nStatistics\n\n\nM248\n\n\nHypothesisTesting\n\n\n\n\nNov 8, 2022\n\n\n\n\n\n11/9/22, 8:25:53 AM\n\n\n\n\n\n\n\n\n\n\nIncarceration Trends\n\n\n\nTidyTuesday\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n11/10/22, 8:57:10 AM\n\n\n\n\n\n\n\n\n\n\nModelling Events In Time\n\n\n\nProbability\n\n\nM343\n\n\nPoissonProcess\n\n\n\n\nNov 6, 2022\n\n\n\n\n\n11/11/22, 4:46:29 AM\n\n\n\n\n\n\n\n\n\n\nPoissonProcesses\n\n\n\nProbability\n\n\nPackage\n\n\n\n\nNov 6, 2022\n\n\n\n\n\n11/6/22, 1:06:22 PM\n\n\n\n\n\n\n\n\n\n\nAdvent of Code 2020\n\n\n\nAdventOfCode\n\n\n\n\nNov 5, 2022\n\n\n\n\n\n11/12/22, 12:25:42 PM\n\n\n\n\n\n\n\n\n\n\nSummarise And Visualise Multivariate Data\n\n\n\nStatistics\n\n\nM249\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n11/3/22, 4:55:08 PM\n\n\n\n\n\n\n\n\n\n\nModelling Continuous Random Variables Using SciPy\n\n\n\nProbability\n\n\nM343\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n11/3/22, 4:54:11 PM\n\n\n\n\n\n\n\n\n\n\nModelling Discrete Random Variables Using SciPy\n\n\n\nProbability\n\n\nM343\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n11/3/22, 4:40:45 PM\n\n\n\n\n\n\n\n\n\n\nPoisson Processes\n\n\n\nProbability\n\n\nM343\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n11/6/22, 10:29:27 AM\n\n\n\n\n\n\n\n\n\n\nAnalysing Cohort And Case-Control Studies\n\n\n\nStatistics\n\n\nM249\n\n\n\n\nOct 30, 2022\n\n\n\n\n\n11/11/22, 11:00:48 AM\n\n\n\n\n\n\n\n\n\n\nGreat British Bakeoff\n\n\n\nTidyTuesday\n\n\n\n\nOct 30, 2022\n\n\n\n\n\n11/11/22, 11:25:35 AM\n\n\n\n\n\n\n\n\n\n\nTidyTuesday Project Tracker\n\n\n\nTidyTuesday\n\n\nRecipe\n\n\n\n\nOct 8, 2022\n\n\n\n\n\n11/6/22, 9:28:24 PM\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20221008-tt_problempicker.html",
    "href": "posts/20221008-tt_problempicker.html",
    "title": "TidyTuesday Project Tracker",
    "section": "",
    "text": "from random import randrange\nimport datetime\nimport pandas as pd\nfrom IPython.core.display import HTML"
  },
  {
    "objectID": "posts/20221008-tt_problempicker.html#history",
    "href": "posts/20221008-tt_problempicker.html#history",
    "title": "TidyTuesday Project Tracker",
    "section": "History",
    "text": "History\n\n\nCode\ntt_projects_df = pd.read_csv(\n    'https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/tidytuesday/project_tracker.csv',  # noqa\n    index_col=0,\n    parse_dates=[2, 3],\n    dayfirst=True\n)\nHTML(tt_projects_df.to_html(render_links=True, escape=False, ))\n\n\n\n\n  \n    \n      \n      project\n      initial date\n      selection date\n      status\n      source\n    \n    \n      #\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      Transit costs\n      2021-01-05\n      2022-11-02\n      in draft\n      https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-01-05\n    \n    \n      2\n      National Park Visits\n      2019-09-17\n      2022-11-04\n      in backlog\n      https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-09-17\n    \n    \n      3\n      French Train stats\n      2019-02-26\n      2022-11-04\n      in draft\n      https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-02-26"
  },
  {
    "objectID": "posts/20221008-tt_problempicker.html#project-picker",
    "href": "posts/20221008-tt_problempicker.html#project-picker",
    "title": "TidyTuesday Project Tracker",
    "section": "Project picker",
    "text": "Project picker\nA recipe to select a random a problem from the #tidytuesday back catalogue.\n\n# set the parameters\nstart_date = datetime.date(2018, 4, 2)\ntoday = datetime.date.today()\noneday = datetime.timedelta(days=1)\n\n# select the candidate day\ndays_between_dates = (today - start_date).days\nrandom_number_of_days = randrange(days_between_dates)\nselected_day = start_date + datetime.timedelta(days=random_number_of_days)\n\n# find the previous tuesday\nwhile selected_day.isoweekday() != 2:\n    selected_day -= oneday\n\nprint(f'Selected project = {selected_day}')\n\nSelected project = 2022-05-10"
  },
  {
    "objectID": "posts/20221030-m249_b1p1_cohort_casecon.html",
    "href": "posts/20221030-m249_b1p1_cohort_casecon.html",
    "title": "Analysing Cohort And Case-Control Studies",
    "section": "",
    "text": "Perform an epidemiological analysis on the results of a cohort or case-control study with two or more categories of exposure using statsmodels and scipy.\nThere are two main questions addressed in this notebook.\n\nHow do we ensure the instance of Table2x2 from statsmodels initialises correctly?\nHow do we handle cases where there are multiple exposures?\n\nBoth of these questions are solved by defining three functions that will handle the transfromation and initialisation of the needed data structures. They aren’t particularly interesting functions, so we don’t discuss them beyond noting what the arguments expect.\nWe then show two worked examples, the first involving a cohort study with two exposures, and the second a case-control study with three exposures. This is a recipe book rather than a theoretical overview, so we don’t discuss the theory or interpretation of the results."
  },
  {
    "objectID": "posts/20221030-m249_b1p1_cohort_casecon.html#dependencies",
    "href": "posts/20221030-m249_b1p1_cohort_casecon.html#dependencies",
    "title": "Analysing Cohort And Case-Control Studies",
    "section": "Dependencies",
    "text": "Dependencies\n\nfrom collections import defaultdict\nimport pandas as pd\nfrom scipy import stats as st\nfrom statsmodels import api as sm\nimport lrdataio\n\n\n%load_ext watermark\n%watermark --iv\n\nscipy      : 1.9.3\nstatsmodels: 0.13.5\nlrdataio   : 0.3.0\npandas     : 1.5.1\n\n\n\n\n%precision 6\n\n'%.6f'"
  },
  {
    "objectID": "posts/20221030-m249_b1p1_cohort_casecon.html#functions",
    "href": "posts/20221030-m249_b1p1_cohort_casecon.html#functions",
    "title": "Analysing Cohort And Case-Control Studies",
    "section": "Functions",
    "text": "Functions\nmask(df: pd.DataFrame, exposure: list, outcome: str) -> pd.DataFrame\n\n\nShow the code\ndef mask(df, exposures, outcome) -> pd.DataFrame:\n    e_dict = defaultdict(lambda: 'not exposed')\n    for n, e in enumerate(exposures):\n        e_dict[e] = f'exposure{n+1}'\n    o_dict = defaultdict(lambda: 'no disease')\n    o_dict[outcome] = 'disease'\n    return (\n        pd.DataFrame()\n        .assign(n=df['n'],\n                exposure=df['exposure'].map(lambda s: e_dict[s]),\n                outcome=df['outcome'].map(lambda s: o_dict[s]))\n        .pivot_table('n', 'exposure', 'outcome')\n    )\n\n\nReturn a masked DataFrame, where the exposures and outcomes columns are relabelled with generic labels.\nPre-conditions:\n\ndf has three columns\n\n‘n’, int, the number of observations\n‘exposures’, str, the exposure category\n‘outcomes’, str, the outcome\n\nexposure is a list of the exposures, sans the reference exposure\noutcome is the label representing a positive outcome, either the disease or the case\n\ncollect_table2x2s(df: pd.DataFrame, exposure: list, outcome: str) -> dict[str, sm.Table2x2]\n\n\nShow the code\ndef collect_tables(df, exposures, outcome) -> dict[str, pd.DataFrame]:\n    masked_df = df.pipe(mask, exposures, outcome)\n    es = [f'exposure{n+1}' for n, e in enumerate(exposures)]\n\n    def filter_exposure(e): return (\n        masked_df\n        .query('exposure in [@e, \"not exposed\"]')\n        .to_numpy()\n    )\n\n    return {e: sm.stats.Table2x2(filter_exposure(e)) for e in es}\n\n\nReturn a dictionary that maps each exposure to an instance of Table2x2. The exposure labels are replaced by the generic labels in the mapping.\nPre-conditions:\n\ndf has three columns\n\n‘n’, int, the number of observations\n‘exposures’, str, the exposure category\n‘outcomes’, str, the outcome\n\nexposure is a list of the exposures, sans the reference exposure\noutcome is the label representing a positive outcome, either the disease or the case\n\nmake_table(df: pd.DataFrame, exposure: list, outcome: str) -> sm.stats.Table\n\n\nShow the code\ndef make_table(df, exposures, outcome) -> sm.stats.Table:\n    arr = (\n        df\n        .pipe(mask, exposures, outcome)\n        .to_numpy()\n    )\n\n    return sm.stats.Table(arr)\n\n\nReturn an instance of statsmodels table.\nThe returned Table is ordered exposure1, exposure2, …, no exposure, where expsoure1, exposure2, …, are the items of exposure.\n\ndf has three columns\n\n‘n’, int, the number of observations\n‘exposures’, str, the exposure category\n‘outcomes’, str, the outcome\n\nexposure is a list of the exposures, sans the reference exposure\noutcome is the label representing a positive outcome, either the disease or the case"
  },
  {
    "objectID": "posts/20221030-m249_b1p1_cohort_casecon.html#two-exposures",
    "href": "posts/20221030-m249_b1p1_cohort_casecon.html#two-exposures",
    "title": "Analysing Cohort And Case-Control Studies",
    "section": "Two exposures",
    "text": "Two exposures\nThe data for this worked example is taken from a cohort study that investigated the association compulsory redundancy (the exposure), and incidences of serious self-harm. (Van Keefe et al, 2002.)\nThe background of the study is…\n\nThe association between unemployment and poor health outcomes is well documented. Significant debate exists as to whether unemployment causes ill health or whether those with poor health find it harder to obtain and maintain employment. Factory closure studies are well placed to comment on causation. The objective of this study was to investigate associations between involuntary job loss, mortality and serious illness.\n\n\nSetup\nCache and load the results into a DataFrame.\n\n_temp_path = lrdataio.cache_url('https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/m249/medical/redundancy_ssi.csv')  # noqa\nredundancy_df = pd.read_csv(_temp_path)\nredundancy_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4 entries, 0 to 3\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   n         4 non-null      int64 \n 1   exposure  4 non-null      object\n 2   outcome   4 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 224.0+ bytes\n\n\n\nredundancy_df\n\n\n\n\n\n  \n    \n      \n      n\n      exposure\n      outcome\n    \n  \n  \n    \n      0\n      14\n      redundant\n      ssi\n    \n    \n      1\n      1931\n      redundant\n      no ssi\n    \n    \n      2\n      4\n      not redundant\n      ssi\n    \n    \n      3\n      1763\n      not redundant\n      no ssi\n    \n  \n\n\n\n\nUse the collect_table2x2s function to collect the instances of Table2x2 as a dict, where each item in the dict maps an exposure to an instance of Table2x2.\nGiven there are only two exposures here, there will be only be a single item in the returned dict. We therefore bypass the dict and directly assign the item to a variable.\n\n_exposures = ['redundant']  # exposure list\n_outcome = 'ssi'\nredundancy_table = (\n    redundancy_df\n    .pipe(collect_tables, _exposures, _outcome)\n    ['exposure1']\n)\n\nOutput the table to ensure they have initialised successfully.\n\nprint(redundancy_table)\n\nA 2x2 contingency table with counts:\n[[  14. 1931.]\n [   4. 1763.]]\n\n\n\n\nMeasures of association\nOutput a summary table of the measures of association.\n\n\n\n\n\n\nNote\n\n\n\nIf you coming here from M249, then we are only interested in the Odds ratio and Risk ratio rows. Also, the risk ratio is the relative risk.\n\n\n\nredundancy_table.summary()\n\n\n\n\n                 Estimate  SE    LCB   UCB  p-value\n\n\n  Odds ratio        3.195       1.050 9.726   0.041\n\n\n  Log odds ratio    1.162 0.568 0.049 2.275   0.041\n\n\n  Risk ratio        3.180       1.049 9.642   0.041\n\n\n  Log risk ratio    1.157 0.566 0.047 2.266   0.041\n\n\n\n\n\n\nTests for no association\n\nChi-squared test\nExpected frequencies under the null hypothesis of no association.\n\nredundancy_table.fittedvalues\n\narray([[   9.431573, 1935.568427],\n       [   8.568427, 1758.431573]])\n\n\nDifferences between the observed and expected frequencies.\n\nredundancy_table.table - redundancy_table.fittedvalues\n\narray([[ 4.568427, -4.568427],\n       [-4.568427,  4.568427]])\n\n\nContributions to the chi-squared test statistic.\n\nredundancy_table.chi2_contribs\n\narray([[2.212836, 0.010783],\n       [2.435747, 0.011869]])\n\n\nChi-squared test result.\n\nprint(redundancy_table.test_nominal_association())\n\ndf          1\npvalue      0.030671871146104812\nstatistic   4.671234588585282\n\n\n\n\nFisher’s exact test\n\n\n\n\n\n\nNote\n\n\n\nThere is no implementation of Fisher’s exact test is statsmodels, so we use scipy implementation.\n\n\n\npd.Series(\n    data=st.fisher_exact(redundancy_table.table)[1],\n    index=['pvalue'],\n    name='fisher''s exact'\n)\n\npvalue    0.033877\nName: fishers exact, dtype: float64"
  },
  {
    "objectID": "posts/20221030-m249_b1p1_cohort_casecon.html#three-or-more-exposures",
    "href": "posts/20221030-m249_b1p1_cohort_casecon.html#three-or-more-exposures",
    "title": "Analysing Cohort And Case-Control Studies",
    "section": "Three or more exposures",
    "text": "Three or more exposures\nData are taken from a cohort study that investigated the association the duration of the pregnancy (the exposure), and incidences of early childhood asthma. (Yuan et al, 2002.)\nThe background of the study is…\n\nChildhood asthma may have a fetal origin. In order to examine this hypothesis we examined the association between fetal growth indicators and hospitalization with asthma during early childhood.\n\n\nSetup\nCache and load the results into a DataFrame.\n\n_temp_path = lrdataio.cache_url('https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/m249/medical/asthmagest.csv')  # noqa\nasthma_df = pd.read_csv(_temp_path)\nasthma_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6 entries, 0 to 5\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   n         6 non-null      int64 \n 1   exposure  6 non-null      object\n 2   outcome   6 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 272.0+ bytes\n\n\n\nasthma_df\n\n\n\n\n\n  \n    \n      \n      n\n      exposure\n      outcome\n    \n  \n  \n    \n      0\n      18\n      pre-term\n      hospitalised\n    \n    \n      1\n      266\n      pre-term\n      not hospitalised\n    \n    \n      2\n      402\n      term\n      hospitalised\n    \n    \n      3\n      8565\n      term\n      not hospitalised\n    \n    \n      4\n      45\n      post-term\n      hospitalised\n    \n    \n      5\n      1100\n      post-term\n      not hospitalised\n    \n  \n\n\n\n\nUse the collect_tables2x2s function to collect the instances of Table2x2 as a dict.\nWe take the ‘term’ exposure to be the reference exposure, so we do not add it to the exposures list.\n\n_exposures = ['pre-term', 'post-term']  # exposure list\n_outcome = 'hospitalised'\nasthma_tables = asthma_df.pipe(collect_tables, _exposures, _outcome)\n\nOutput the tables to ensure they have initialised successfully.\n\nfor e, t in asthma_tables.items():\n    print(f'exposure={e}')\n    print(t, '\\n')\n\nexposure=exposure1\nA 2x2 contingency table with counts:\n[[  18.  266.]\n [ 402. 8565.]] \n\nexposure=exposure2\nA 2x2 contingency table with counts:\n[[  45. 1100.]\n [ 402. 8565.]] \n\n\n\n\n\nMeasures of association\nOutput two summary tables, one for each exposure.\n\n\n\n\n\n\nNote\n\n\n\nThis is a case-control study, so only the Odds ratio is relevant.\n\n\n\nfor e, t in asthma_tables.items():\n    print(f'exposure={e}')\n    print(t.summary(), '\\n')\n\nexposure=exposure1\n               Estimate   SE   LCB    UCB  p-value\n--------------------------------------------------\nOdds ratio        1.442        0.885 2.348   0.141\nLog odds ratio    0.366 0.249 -0.122 0.854   0.141\nRisk ratio        1.414        0.895 2.233   0.138\nLog risk ratio    0.346 0.233 -0.111 0.803   0.138\n-------------------------------------------------- \n\nexposure=exposure2\n               Estimate   SE   LCB    UCB  p-value\n--------------------------------------------------\nOdds ratio        0.872        0.636 1.194   0.392\nLog odds ratio   -0.137 0.160 -0.452 0.177   0.392\nRisk ratio        0.877        0.648 1.186   0.393\nLog risk ratio   -0.132 0.154 -0.434 0.170   0.393\n-------------------------------------------------- \n\n\n\n\n\nTests for no association\n\nChi-squared test\nInitialise the instance of Table.\n\n_exposures = ['pre-term', 'post-term']  # exposure list\n_outcome = 'hospitalised'\nasthma_table = asthma_df.pipe(make_table, _exposures, _outcome)\n\nOutput the table to ensure they have initialised successfully.\n\n\n\n\n\n\nNote\n\n\n\nThe rows are ordered: pre-term, post-term, term, and columns are ordered hospitalised, not hospitalised.\n\n\n\nprint(asthma_table)\n\nA 3x2 contingency table with counts:\n[[  18.  266.]\n [  45. 1100.]\n [ 402. 8565.]]\n\n\nExpected frequencies under the null hypothesis of no association.\n\nasthma_table.fittedvalues\n\narray([[  12.702963,  271.297037],\n       [  51.214409, 1093.785591],\n       [ 401.082628, 8565.917372]])\n\n\nDifferences between the observed and expected frequencies.\n\nasthma_table.table - asthma_table.fittedvalues\n\narray([[ 5.297037, -5.297037],\n       [-6.214409,  6.214409],\n       [ 0.917372, -0.917372]])\n\n\nContributions to the chi-squared test statistic.\n\nasthma_table.chi2_contribs\n\narray([[2.208824e+00, 1.034239e-01],\n       [7.540629e-01, 3.530755e-02],\n       [2.098250e-03, 9.824651e-05]])\n\n\nChi-squared test result.\n\nprint(asthma_table.test_nominal_association())\n\ndf          2\npvalue      0.21184355211692685\nstatistic   3.1038144769010287"
  },
  {
    "objectID": "posts/20221030-m249_b1p1_cohort_casecon.html#references",
    "href": "posts/20221030-m249_b1p1_cohort_casecon.html#references",
    "title": "Analysing Cohort And Case-Control Studies",
    "section": "References",
    "text": "References\nKeefe V, Reid P, Ormsby C, et al. Serious health events following involuntary job loss in New Zealand meat processing workers. Int J Epidemiol. 2002;31(6):1155-1161 doi:10.1093/ije/31.6.1155\nYuan W, Basso O, Sorensen HT, Olsen J. Fetal growth and hospitalization with asthma during early childhood: a follow-up study in Denmark. Int J Epidemiol. 2002;31(6):1240-1245. doi:10.1093/ije/31.6.1240"
  },
  {
    "objectID": "posts/20221030-tt_great_british_bakeoff.html",
    "href": "posts/20221030-tt_great_british_bakeoff.html",
    "title": "Great British Bakeoff",
    "section": "",
    "text": "Visualising the Great British Bakeoff with #TidyTuesday | source.\nWe follow the examples given in Data Visualization in the Tidyverse - The Great Tidy Plot Off by Alison Hill."
  },
  {
    "objectID": "posts/20221030-tt_great_british_bakeoff.html#dependencies",
    "href": "posts/20221030-tt_great_british_bakeoff.html#dependencies",
    "title": "Great British Bakeoff",
    "section": "Dependencies",
    "text": "Dependencies\n\nimport pandas as pd\nfrom seaborn import objects as so\nfrom matplotlib import style\nimport lrdataio\n\n\n%load_ext watermark\n%watermark -iv\n\nseaborn   : 0.12.1\npandas    : 1.4.4\nlrdataio  : 0.3.0\nmatplotlib: 3.6.0"
  },
  {
    "objectID": "posts/20221030-tt_great_british_bakeoff.html#cache-and-load-the-data",
    "href": "posts/20221030-tt_great_british_bakeoff.html#cache-and-load-the-data",
    "title": "Great British Bakeoff",
    "section": "Cache and load the data",
    "text": "Cache and load the data\n\nratings_df = pd.read_csv(lrdataio.cache_url('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-25/ratings.csv'))  # noqa\nratings_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 94 entries, 0 to 93\nData columns (total 11 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   series                94 non-null     int64  \n 1   episode               94 non-null     int64  \n 2   uk_airdate            94 non-null     object \n 3   viewers_7day          94 non-null     float64\n 4   viewers_28day         93 non-null     float64\n 5   network_rank          70 non-null     float64\n 6   channels_rank         50 non-null     float64\n 7   bbc_iplayer_requests  20 non-null     float64\n 8   episode_count         94 non-null     int64  \n 9   us_season             50 non-null     float64\n 10  us_airdate            45 non-null     object \ndtypes: float64(6), int64(3), object(2)\nmemory usage: 8.2+ KB"
  },
  {
    "objectID": "posts/20221030-tt_great_british_bakeoff.html#how-has-the-viewership-changed",
    "href": "posts/20221030-tt_great_british_bakeoff.html#how-has-the-viewership-changed",
    "title": "Great British Bakeoff",
    "section": "How has the viewership changed?",
    "text": "How has the viewership changed?\n\nseries8_decline\n\nseries8_decline = (\n    ratings_df\n    .query('1 <= series <= 8')\n    .assign(series=lambda x: x['series'].astype(str))\n)\n\n\n\nContinuous bar chart\n\n\nShow the code\ndef _plot_cts_bar_chart(df: pd.DataFrame) -> None:\n    series_text = (\n        pd.DataFrame()\n        .assign(\n            episode_count=df.groupby('series')['episode_count'].mean(),\n            viewers_7day=df.groupby('series')['viewers_7day'].median()\n        )\n        .reset_index()\n    )\n    return (\n        so.Plot(df,\n                x='episode_count',\n                y='viewers_7day',\n                color='series',\n                text='series')\n        .add(so.Bars(), legend=False)\n        .add(so.Text(color='black',\n                     valign='bottom',\n                     offset=10),\n             data=series_text)\n        .scale(x=so.Continuous().label(like=lambda _, __: ''), color='muted')\n        .label(x='')\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nseries8_decline.pipe(_plot_cts_bar_chart)\n\n\n\n\n\n\n\nFaceted line chart\n\n\nShow the code\ndef _plot_faceted_line_chart(df: pd.DataFrame) -> None:\n    return (\n        so.Plot(df,\n                x='episode',\n                y='viewers_7day',\n                color='series')\n        .add(so.Line(), legend=False)\n        .scale(x=so.Continuous().label(like=lambda _, __: ''),\n               color='muted')\n        .facet(col='series', wrap=4)\n        .label(x='')\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nseries8_decline.pipe(_plot_faceted_line_chart)"
  },
  {
    "objectID": "posts/20221030-tt_great_british_bakeoff.html#premieres-vs.-finales",
    "href": "posts/20221030-tt_great_british_bakeoff.html#premieres-vs.-finales",
    "title": "Great British Bakeoff",
    "section": "Premieres vs. Finales",
    "text": "Premieres vs. Finales\n\nfirst_last\n\nfirst = ratings_df.query('episode == 1 and (1 <= series <= 8)')\nlast = (\n    ratings_df\n    .query('1 <= series <= 8')\n    .sort_values(by=['episode', 'series'],\n                 ascending=[False, True])\n    .drop_duplicates('series')\n)\nfirst_last = (\n    pd.concat([first, last])\n    .assign(episode=lambda x: x['episode'].apply(\n                lambda s: ('first' if s == 1 else 'last')),\n            series=lambda x: x['series'].astype(str))\n)\n\n\n\nfinale_pct_bump\n\nfinale_pct_bump = (\n    first_last\n    .set_index('series')\n    .groupby('series')['viewers_7day'].pct_change()\n    .rename('prop_bump')\n    .dropna()\n    .to_frame()\n    .assign(pct_bump=lambda x: (x['prop_bump'] * 100).round(1))\n    .sort_index(ascending=False)\n)\n\n\n\nDumbbell plot\n\n\nShow the code\ndef _plot_dumbbell(df) -> so.Plot:\n    return (\n        so.Plot(df,\n                x='viewers_7day',\n                y='series',\n                group='series',\n                text='series')\n        .add(so.Line(), legend=None)\n        .add(so.Line(linewidth=0, marker='o', pointsize=8),\n             color='episode',\n             data=df)\n        .scale(color='tab10')\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nfirst_last.pipe(_plot_dumbbell)\n\n\n\n\n\n\n\nSlope graph\n\n\nShow the code\ndef _plot_slope(df) -> so.Plot:\n    return (\n        so.Plot(df,\n                x='episode',\n                y='viewers_7day',\n                color='series',\n                text='series')\n        .add(so.Line(marker='o',\n                     pointsize=8),\n             legend=None)\n        .add(so.Text(halign=\"left\",\n                     offset=20),\n             data=df.query('episode == \"last\"'))\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nfirst_last.pipe(_plot_slope)\n\n\n\n\n\n\n\nBar chart with median line\n\n\nShow the code\ndef _plot_bar_hax_line(df) -> so.Plot:\n    med_line = df.assign(pct_bump=[df['pct_bump'].median()] * 8)\n    return (\n        so.Plot(df, x='pct_bump', y='series')\n        .add(so.Bar(),\n             orient='h')\n        .add(so.Line(color='r',\n                     linestyle='dashed'),\n             data=med_line,\n             orient='h')\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nfinale_pct_bump.pipe(_plot_bar_hax_line)\n\n\n\n\n\n\n\nLollipop chart with median line\n\n\nShow the code\ndef _plot_lollipop_hax_line(df) -> so.Plot:\n    df = df.sort_index()\n    med_line = df.assign(pct_bump=[df['pct_bump'].median()] * 8)\n    return (\n        so.Plot(df,\n                x='series',\n                y='pct_bump')\n        .add(so.Bars(width=0.05))\n        .add(so.Dot(pointsize=8))\n        .add(so.Line(color='r',\n                     linestyle='dashed'),\n             data=med_line)\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nfinale_pct_bump.pipe(_plot_lollipop_hax_line)\n\n\n\n\n\n\n\nPop-Out Scatterplot\n\n\nShow the code\ndef _plot_scatter_pop_out(df) -> so.Plot:\n    df = (\n        df\n        .pivot(index='series',\n               columns='episode',\n               values='viewers_7day')\n        .reset_index()\n    )\n    return (\n        so.Plot(df,\n                x='first',\n                y='last',\n                text='series')\n        .add(so.Dots(pointsize=8))\n        .add(so.Dot(pointsize=8, color='r'),\n             data=df.query('series == \"8\"'))\n        .add(so.Text(halign='left',\n                     offset=10))\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\nfirst_last.pipe(_plot_scatter_pop_out)"
  },
  {
    "objectID": "posts/20221102-m249_b3p1_summarise_mv_data.html",
    "href": "posts/20221102-m249_b3p1_summarise_mv_data.html",
    "title": "Summarise And Visualise Multivariate Data",
    "section": "",
    "text": "How to summarise and visualise multivariate data using pandas and seaborn.\nWe used the iris dataset for this cookbook.\nThis was a fairly dry notebook, but many of its recipes will be used throughout the other notes on this topic.\nGroup standardisation is not addressed in this notebook. That topic will be address in a separate notebook given its complexity.\nThis topic is covered in the Open University’s M249, Book 3, Part I.\n\nimport pandas as pd\nfrom statsmodels import datasets\nfrom sklearn import preprocessing\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom seaborn import objects as so\n\n\n%load_ext watermark\n%watermark -iv\n\nstatsmodels: 0.13.2\npandas     : 1.5.1\nsklearn    : 0.0\nmatplotlib : 3.6.1\nseaborn    : 0.12.1\n\n\n\n\nsns.set_theme()"
  },
  {
    "objectID": "posts/20221102-m249_b3p1_summarise_mv_data.html#setup",
    "href": "posts/20221102-m249_b3p1_summarise_mv_data.html#setup",
    "title": "Summarise And Visualise Multivariate Data",
    "section": "Setup",
    "text": "Setup\n\nLoad the data\nReturn iris, DataFrame, a representation of the Iris dataset.\n\niris_df = datasets.get_rdataset('iris', cache=True).data\n\nConfirm iris has initialised as expected.\n\niris_df.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Sepal.Length  150 non-null    float64\n 1   Sepal.Width   150 non-null    float64\n 2   Petal.Length  150 non-null    float64\n 3   Petal.Width   150 non-null    float64\n 4   Species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\n\n\nCheck the head and the tail.\n\niris_df.head(3)\n\n\n\n\n\n  \n    \n      \n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n      Species\n    \n  \n  \n    \n      0\n      5.1\n      3.5\n      1.4\n      0.2\n      setosa\n    \n    \n      1\n      4.9\n      3.0\n      1.4\n      0.2\n      setosa\n    \n    \n      2\n      4.7\n      3.2\n      1.3\n      0.2\n      setosa\n    \n  \n\n\n\n\n\niris_df.tail(3)\n\n\n\n\n\n  \n    \n      \n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n      Species\n    \n  \n  \n    \n      147\n      6.5\n      3.0\n      5.2\n      2.0\n      virginica\n    \n    \n      148\n      6.2\n      3.4\n      5.4\n      2.3\n      virginica\n    \n    \n      149\n      5.9\n      3.0\n      5.1\n      1.8\n      virginica\n    \n  \n\n\n\n\n\n\nTake views of the data\nAssign ‘Species’, the name of the group variable, to variable G.\n\nG = 'Species'\n\nTake two views of iris_df: XG will contain all the variables, including the group variable G, and X will be a view of iris_df without G.\n\nXG = iris_df\n\n\nX = iris_df.drop(columns=G)"
  },
  {
    "objectID": "posts/20221102-m249_b3p1_summarise_mv_data.html#summarising-the-data",
    "href": "posts/20221102-m249_b3p1_summarise_mv_data.html#summarising-the-data",
    "title": "Summarise And Visualise Multivariate Data",
    "section": "Summarising the data",
    "text": "Summarising the data\n\nDescribe the data\n\nDescribe the ungrouped data\n\nX.describe().T[['mean', 'std']]\n\n\n\n\n\n  \n    \n      \n      mean\n      std\n    \n  \n  \n    \n      Sepal.Length\n      5.843333\n      0.828066\n    \n    \n      Sepal.Width\n      3.057333\n      0.435866\n    \n    \n      Petal.Length\n      3.758000\n      1.765298\n    \n    \n      Petal.Width\n      1.199333\n      0.762238\n    \n  \n\n\n\n\n\n\nDescribe the grouped data\n\n(\n    XG\n    .groupby(G)\n    .describe()\n    .T[lambda a: a.index.get_level_values(1).isin(['mean', 'std'])]\n    .T\n)\n\n\n\n\n\n  \n    \n      \n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n    \n    \n      \n      mean\n      std\n      mean\n      std\n      mean\n      std\n      mean\n      std\n    \n    \n      Species\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      setosa\n      5.006\n      0.352490\n      3.428\n      0.379064\n      1.462\n      0.173664\n      0.246\n      0.105386\n    \n    \n      versicolor\n      5.936\n      0.516171\n      2.770\n      0.313798\n      4.260\n      0.469911\n      1.326\n      0.197753\n    \n    \n      virginica\n      6.588\n      0.635880\n      2.974\n      0.322497\n      5.552\n      0.551895\n      2.026\n      0.274650\n    \n  \n\n\n\n\n\n\n\nMean vectors\n\nReturn the mean vector\n\nX.mean()\n\nSepal.Length    5.843333\nSepal.Width     3.057333\nPetal.Length    3.758000\nPetal.Width     1.199333\ndtype: float64\n\n\n\n\nReturn the grouped mean vectors\n\nXG.groupby(G).mean()\n\n\n\n\n\n  \n    \n      \n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n    \n    \n      Species\n      \n      \n      \n      \n    \n  \n  \n    \n      setosa\n      5.006\n      3.428\n      1.462\n      0.246\n    \n    \n      versicolor\n      5.936\n      2.770\n      4.260\n      1.326\n    \n    \n      virginica\n      6.588\n      2.974\n      5.552\n      2.026\n    \n  \n\n\n\n\n\n\n\nCorrelation and covariance matrices\n\n# correlation matrix\nX.corr()\n\n\n\n\n\n  \n    \n      \n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n    \n  \n  \n    \n      Sepal.Length\n      1.000000\n      -0.117570\n      0.871754\n      0.817941\n    \n    \n      Sepal.Width\n      -0.117570\n      1.000000\n      -0.428440\n      -0.366126\n    \n    \n      Petal.Length\n      0.871754\n      -0.428440\n      1.000000\n      0.962865\n    \n    \n      Petal.Width\n      0.817941\n      -0.366126\n      0.962865\n      1.000000\n    \n  \n\n\n\n\n\n# covariance matrix\nX.cov()\n\n\n\n\n\n  \n    \n      \n      Sepal.Length\n      Sepal.Width\n      Petal.Length\n      Petal.Width\n    \n  \n  \n    \n      Sepal.Length\n      0.685694\n      -0.042434\n      1.274315\n      0.516271\n    \n    \n      Sepal.Width\n      -0.042434\n      0.189979\n      -0.329656\n      -0.121639\n    \n    \n      Petal.Length\n      1.274315\n      -0.329656\n      3.116278\n      1.295609\n    \n    \n      Petal.Width\n      0.516271\n      -0.121639\n      1.295609\n      0.581006\n    \n  \n\n\n\n\n\n\nStandardisation\nStandardise the data and assign to variable Z.\n\nscaler = preprocessing.StandardScaler()\nZ = (\n    pd.DataFrame(scaler.fit_transform(X))\n    .rename(columns={n: c for n, c in enumerate(X.columns)})\n)\nZ.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Sepal.Length  150 non-null    float64\n 1   Sepal.Width   150 non-null    float64\n 2   Petal.Length  150 non-null    float64\n 3   Petal.Width   150 non-null    float64\ndtypes: float64(4)\nmemory usage: 4.8 KB\n\n\nConfirm the mean and standard deviation of each variable are approximately (0, 1).\n\nZ.describe().T[['mean', 'std']]\n\n\n\n\n\n  \n    \n      \n      mean\n      std\n    \n  \n  \n    \n      Sepal.Length\n      -4.736952e-16\n      1.00335\n    \n    \n      Sepal.Width\n      -7.815970e-16\n      1.00335\n    \n    \n      Petal.Length\n      -4.263256e-16\n      1.00335\n    \n    \n      Petal.Width\n      -4.736952e-16\n      1.00335\n    \n  \n\n\n\n\nAdd the grouping variable to Z, and bind this new view to variable ZG.\n\nZG = Z.assign(Species=XG[G])\nZG.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Sepal.Length  150 non-null    float64\n 1   Sepal.Width   150 non-null    float64\n 2   Petal.Length  150 non-null    float64\n 3   Petal.Width   150 non-null    float64\n 4   Species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB"
  },
  {
    "objectID": "posts/20221102-m249_b3p1_summarise_mv_data.html#visualising-multivariate-data",
    "href": "posts/20221102-m249_b3p1_summarise_mv_data.html#visualising-multivariate-data",
    "title": "Summarise And Visualise Multivariate Data",
    "section": "Visualising multivariate data",
    "text": "Visualising multivariate data\n\nGrouped scatterplots\n\ndef plot_grouped_scatter(df, g, x1, x2) -> so.Plot:\n    return (\n        so.Plot(df, x=x1, y=x2, color=g, marker=g)\n        .add(so.Dots())\n    )\n\n\nZG.pipe(plot_grouped_scatter, G, 'Petal.Length', \"Sepal.Length\")\n\n\n\n\n\n\nGrouped scatterplots with marginal distributions\n\nsns.jointplot(data=ZG, x=\"Petal.Width\", y=\"Sepal.Length\", hue=G)\nplt.show()\n\n\n\n\n\n\nMatrix scatterplot\n\nsns.pairplot(data=ZG, hue=G, height=2)\nplt.show()\n\n\n\n\n\n\nHeatmaps\n\nHeatmap of the correlation matrix.\n\n# correlation heatmap\nsns.heatmap(Z.corr(), annot=True, vmin=-1, vmax=1, cmap='bwr', square=True)\nplt.title('Correlation heatmap')\nplt.show()\n\n\n\n\n\n\nHeatmap of the covariance matrix.\n\n# covariance heatmap\n# find the max |cov| so we can standardise the scale\nb = X.cov().melt()['value'].apply(abs).max()\n\nsns.heatmap(X.cov(), annot=True, vmin=-b, vmax=b, cmap='bwr', square=True)\nplt.title('Covariance heatmap')\nplt.show()\n\n\n\n\n\n\n\nData profiles\n\nProfile plot\n\ndef plot_profile(df):\n    return (\n        so.Plot(df.mean().reset_index(), x='index', y=0)\n        .add(so.Line(marker='o'))\n        .label(x='variable', y='value')\n    )\n\n\nX.pipe(plot_profile)\n\n\n\n\n\n\nStrip plot\n\ndef plot_grouped_profile(df):\n    return (\n        so.Plot(df.melt(), x='variable', y='value')\n        .add(so.Dots(), so.Jitter())\n    )\n\n\nX.pipe(plot_grouped_profile)\n\n\n\n\n\n\nGrouped profile plot\n\ndef plot_grouped_profile(df, g):\n    return (\n        so.Plot(df.melt(id_vars=G), x='variable', y='value', color=G)\n        .add(so.Line(marker='o'), so.Est())\n        .add(so.Band())\n    )\n\n\nXG.pipe(plot_grouped_profile, G)\n\n\n\n\n\n\nGrouped strip plot\n\ndef plot_grouped_profile(df, g):\n    return (\n        so.Plot(df.melt(id_vars=G), x='variable', y='value', marker=G, color=G)\n        .add(so.Dots(), so.Jitter())\n    )\n\n\nXG.pipe(plot_grouped_profile, G)"
  },
  {
    "objectID": "posts/20221102-m343_b1ii_continuous_rv.html",
    "href": "posts/20221102-m343_b1ii_continuous_rv.html",
    "title": "Modelling Continuous Random Variables Using SciPy",
    "section": "",
    "text": "How to use scipy’s scipy.stats.rv_continuous class to model a continuous random variable. The scenario is taken from M343 Book 1, Section 4, where we model the time taken to perform an oil change."
  },
  {
    "objectID": "posts/20221102-m343_b1ii_continuous_rv.html#define-and-initialise-the-random-variable",
    "href": "posts/20221102-m343_b1ii_continuous_rv.html#define-and-initialise-the-random-variable",
    "title": "Modelling Continuous Random Variables Using SciPy",
    "section": "Define and initialise the random variable",
    "text": "Define and initialise the random variable\nWe declare a new subclass of rv_continuous, and override the _pdf method.\n\nclass oil_change_gen(st.rv_continuous):\n    def _pdf(self, t):\n        return t / 48\n\nInitialise the random variable.\n\n\n\n\n\n\nNote\n\n\n\nArguments a, b refer to the min, max values of the random variable. If either are (-inf, inf), then you do not need to pass an argument for it.\n\n\n\nrv_oil_change = oil_change_gen(a=2, b=10)\n\n\nPlot the random variable\nGet the event space of the random variable.\n\nts = np.linspace(rv_oil_change.ppf(0.01), rv_oil_change.ppf(0.99), num=100)\n\nPlot the probability density function.\n\n(\n    so.Plot(x=ts, y=rv_oil_change.pdf(ts))\n    .add(so.Line())\n    .label(x='T',\n           y='f(t)',\n           title='Probability distribution')\n)\n\n\n\n\nPlot the cumulative distribution function.\n\n(\n    so.Plot(x=ts, y=rv_oil_change.cdf(ts))\n    .add(so.Line())\n    .label(x='T',\n           y='f(t)',\n           title='Cumulative distribution')\n)\n\n\n\n\n\n\nCalculating probabilities\n(a) Return the probability that an oil change takes six minutes or less.\n\nrv_oil_change.cdf(6)\n\n0.3333\n\n\n(b) Find the probability that an oil change takes more than six minutes but less than seven minutes.\n\nrv_oil_change.cdf(7) - rv_oil_change.cdf(6)\n\n0.1354\n\n\n(c) Calculate the probability that an oil change takes longer than 3.5 minutes.\n\nrv_oil_change.sf(3.5)\n\n0.9141\n\n\n\n\nLocation and spread\n(a) Return the mean and median.\n\nrv_oil_change.mean(), rv_oil_change.median()\n\n(6.8889, 7.2111)\n\n\n(b) Return the standard deviation, variance, and interquartile range.\n\ndef iqr(rv): return rv.ppf(0.75) - rv.ppf(0.25)\n\n\nrv_oil_change.std(), rv_oil_change.var(), iqr(rv_oil_change)\n\n(2.1315, 4.5432, 3.4263)\n\n\n\n\nCalculating quantiles\n(a) Return the 0.9-quantile.\n\nrv_oil_change.ppf(0.9)\n\n9.5079\n\n\n(b) Return the quartiles.\n\nrv_oil_change.ppf([0.25, 0.5, 0.75])\n\narray([5.2915, 7.2111, 8.7178])\n\n\n\n\nSampling the distribution\nGenerate a sample of times.\n\nrv_oil_change.rvs(size=5)\n\narray([2.4846, 8.9973, 8.8444, 9.2723, 7.9823])\n\n\nPlot a frequency histogram of a sample of size n=1000.\n\n(\n    so.Plot(x=rv_oil_change.rvs(size=1000))\n    .add(so.Bar(), so.Hist(), so.Dodge(gap=-0.2))  # reduce gap between bars\n    .label(x='T', title='Sample')\n    .label(title='Frequency histogram (n=1000)')\n)"
  },
  {
    "objectID": "posts/20221102-m343_b1i_discrete_rv.html",
    "href": "posts/20221102-m343_b1i_discrete_rv.html",
    "title": "Modelling Discrete Random Variables Using SciPy",
    "section": "",
    "text": "How to use scipy’s scipy.stats.rv_discrete class to model a discrete random variable.\nThis is a practical notebook rather than a theoretical one, and is intended to be a whistle-stop tour of rv_discrete using a non-trivial scenario.\nThe naming convention used to represent the different data structures is based on SciPy’s various worked examples.\nThe scenario is based on M343 Book 1, Example 2.2 (Rolling two dice: independent random variables).\n\nimport itertools as it\nfrom collections import Counter\nimport pandas as pd\nfrom scipy import stats as st\nfrom seaborn import objects as so\n\n\n%load_ext watermark\n%watermark -iv\n\nscipy  : 1.9.3\npandas : 1.5.1\nseaborn: 0.12.1\n\n\n\nLower the precision of the output.\n\n%precision 4\n\n'%.4f'\n\n\n\n\nTo initialise an instance of rv_discrete, we requires the event space and the probability associated with each event.\nInitialise 2 random variables, one to represent the red die and the other the blue die.\n\ndice = [[roll+1 for roll in range(6)] for die in range(2)]\n\nGet all possible outcomes from rolling the two dice by taking their caretesian product.\n\ndice_rolls = [*it.product(*dice)]\n\nCollect all the possible scores from rolling the two die. (This our event space.)\n\nscores = [sum(dice_roll) for dice_roll in dice_rolls]\n\nUse a Counter to count the number of times each event occurs.\n\nk_scores = Counter(scores)\n\nCollect xk, the event space, and pk, the probability of each event.\n\nxk = [*k_scores.keys()]\npk = [k_score / k_scores.total() for k_score in k_scores.values()]\n\n\n\n\nInitialise rv_score, rv_discrete, a random variable that represents the score from rolling two die and summing the scores.\n\nrv_score = st.rv_discrete(values=(xk, pk))\n\n\n\n\nPlot the p.m.f. and c.d.f.\n\n(\n    so.Plot(x=xk,\n            y=rv_score.pmf(xk))\n    .add(so.Bar())\n    .label(x='X',\n           y='p(x)',\n           title='Probability distribution')\n)\n\n\n\n\n\n(\n    so.Plot(x=xk, y=rv_score.cdf(xk))\n    .add(so.Bar())\n    .label(x='X',\n           y='F(x)',\n           title='Cumulative distribution')\n)\n\n\n\n\n\n\n\nOutput a probability table.\n\n(\n    pd.DataFrame()\n    .set_axis(pd.Index(xk, name='score'))\n    .assign(pdf=rv_score.pmf(xk),\n            cdf=rv_score.cdf(xk))\n)\n\n\n\n\n\n  \n    \n      \n      pdf\n      cdf\n    \n    \n      score\n      \n      \n    \n  \n  \n    \n      2\n      0.027778\n      0.027778\n    \n    \n      3\n      0.055556\n      0.083333\n    \n    \n      4\n      0.083333\n      0.166667\n    \n    \n      5\n      0.111111\n      0.277778\n    \n    \n      6\n      0.138889\n      0.416667\n    \n    \n      7\n      0.166667\n      0.583333\n    \n    \n      8\n      0.138889\n      0.722222\n    \n    \n      9\n      0.111111\n      0.833333\n    \n    \n      10\n      0.083333\n      0.916667\n    \n    \n      11\n      0.055556\n      0.972222\n    \n    \n      12\n      0.027778\n      1.000000\n    \n  \n\n\n\n\n(a) Return the probability you roll snake eyes.\n\nrv_score.pmf(2)\n\n0.0278\n\n\n(b) Return the probability you roll 6 or less.\n\nrv_score.cdf(6)\n\n0.4167\n\n\n(c) Return the probability your score is 7 or greater.\n\nrv_score.sf(6)  # P(X>=7) == P(X>6)\n\n0.5833\n\n\n\n\n\n(a) Return the mean, median, and modal score.\n\nrv_score.mean(), rv_score.median(), st.mode(scores, keepdims=False).mode\n\n(7.0000, 7.0000, 7)\n\n\n(b) Return the standard deviation, variance, and interquartile range.\n\ndef iqr(rv): return rv.ppf(0.75) - rv.ppf(0.25)\n\n\nrv_score.std(), rv_score.var(), iqr(rv_score)\n\n(2.4152, 5.8333, 4.0000)\n\n\n\n\n\n(a) Return the 0.1-quantile.\n\nrv_score.ppf(0.1)\n\n4.0000\n\n\n(b) Return the quartiles.\n\nrv_score.ppf([0.25, 0.5, 0.75])\n\narray([5., 7., 9.])\n\n\n\n\n\nGenerate a sample of scores.\n\nrv_score.rvs(size=9)\n\narray([11,  6,  5,  5,  5, 11,  4,  6,  5])\n\n\nPlot a frequency distribution of a sample of size n=1000.\n\n(\n    so.Plot(x=rv_score.rvs(size=1000))\n    .add(so.Bar(), so.Count())\n    .label(x='X', y='frequency')\n    .label(title='Frequency distribution (n=1000)')\n)"
  },
  {
    "objectID": "posts/20221102-m343_b2p1ii_poiss_proc.html",
    "href": "posts/20221102-m343_b2p1ii_poiss_proc.html",
    "title": "Poisson Processes",
    "section": "",
    "text": "How to model a Poisson processes using the poissonprocesses module.\n\nfrom poissonprocesses import Events\nimport numpy as np\nimport pandas as pd\nfrom seaborn import objects as so\n\n\n%load_ext watermark\n%watermark -iv\n\nseaborn: 0.12.1\nnumpy  : 1.23.3\npandas : 1.5.1\n\n\n\n\n%precision 4\n\n'%.4f'"
  },
  {
    "objectID": "posts/20221102-m343_b2p1ii_poiss_proc.html#functions",
    "href": "posts/20221102-m343_b2p1ii_poiss_proc.html#functions",
    "title": "Poisson Processes",
    "section": "Functions",
    "text": "Functions\nWe’ll define a couple of plotting functions that will be used throughout the notebook.\n\nplot_n_events(ne: rv_discrete, step: int = 1)\n\n\nShow the code\ndef plot_n_events(ne, step: int = 1) -> so.Plot:\n    \"\"\"Plot the approximated probability distribution for N(t),\n    the number of events in time.\n\n    It's approximate because the event space is 0.01-to-0.99-quantiles.\n\n    Pass step to reduce the number of events plotted, if the returned\n    plot is cluttered.\n    \"\"\"\n    ns = np.arange(ne.ppf(0.01), ne.ppf(0.99), step=step)\n    return (\n        so.Plot(x=ns, y=ne.pmf(ns))\n        .add(so.Bar())\n        .label(x='n', y='p(n)', title='Probability distribution')\n    )\n\n\n\n\nplot_n_events(ne: rv_discrete, step: int = 1)\n\n\nShow the code\ndef plot_waiting_time(wt) -> so.Plot:\n    \"\"\"Plot the approximate probability distribution for T, the waiting\n    time between events.\n\n    It's approximate because the event space is 0.01-to-0.99-quantiles.\n    \"\"\"\n    ts = np.linspace(wt.ppf(0.01), wt.ppf(0.99))\n    return(\n        so.Plot(x=ts, y=wt.pdf(ts))\n        .add(so.Line())\n        .label(x='t', y='f(t)', title='Probability distribution')\n    )\n\n\n\n\n1. Nerve impulses\nM343 Book 2, Activity 3.1\nInitialise impulses, Event, a Poisson process model for the incidence of impulses.\n\nimpulses = Events(458)  # per second\nprint(impulses)\n\nEvents(rate=458)\n\n\nPlot the models for \\(N(t)\\), the number of events in time, and \\(T\\), the time between events.\n\nplot_n_events(impulses.n_events(), step=4)\n\n\n\n\n\nplot_waiting_time(impulses.waiting_time())\n\n\n\n\n(a) Return the probability that not more than one nerve impulse occurs in an interval of 1/100 second.\n\nimpulses.n_events(0.01).cdf(1)\n\n0.0572\n\n\n(b) Return the probability that the interval between two successive impulses is less than 1/1000 second.\n\nimpulses.waiting_time().cdf(0.001)\n\n0.3675\n\n\n\n\n2. Major earthquakes\nM343 Book 2, Activity 3.2\nInitialise earthquakes, Event, a Poisson process model for the incidence of major earthquakes worldwide.\n\nearthquakes = Events(12/14)  # per year\n\nPlot the probability distribution for the number of earthquakes expected in 10 years.\n\nplot_n_events(earthquakes.n_events(10))\n\n\n\n\n\nplot_waiting_time(earthquakes.waiting_time())\n\n\n\n\n(a) Return the probability that there will be at least three major earthquakes in a period of ten years.\n\nearthquakes.n_events(1).sf(2)\n\n0.0560\n\n\n(b) Return the probability that the waiting time between successive major earthquakes exceeds two years.\n\nearthquakes.waiting_time().sf(0.001)\n\n0.9991\n\n\n\n\n3. Some poisson process\nM343 Book 2, Exercise 3.1\nInitialise events, Events, a Poisson process model for the incidence ofsome event.\n\nevents = Events(60/16)  # per hour\n\nPlot the models.\n\nplot_n_events(events.n_events())\n\n\n\n\n\nplot_waiting_time(events.waiting_time())\n\n\n\n\n(c) If there were seven events between 2pm and 3pm yesterday, calculate the probability that there was at most one event between 3pm and 4pm.\n(These are independent events and Poisson processes are memoryless, so what happened between 2pm and 3pm has no bearing on the events between 3pm and 4pm.)\n\nevents(1).cdf(1)\n\n0.1117\n\n\n(d) Return the probability that the waiting time between successive events will exceed half an hour.\n\nevents[:].sf(0.5)\n\n0.1534\n\n\n\n\n4. Volcanic eruptions\nM343 Book 2, Exercise 3.2\nInitialise eruptions, Events, a Poisson process model for the incidence of major volcanic eruptions in the northern hemisphere.\n\neruptions = Events(12/29)  # per year\n\nPlot the models.\n\nplot_n_events(eruptions.n_events(5))\n\n\n\n\n\nplot_waiting_time(eruptions.waiting_time())\n\n\n\n\n(a) Return the expected number of eruptions during a five-year period.\n\neruptions.n_events(5).mean()\n\n2.0690\n\n\n(b) Return the probability that there are exactly two eruptions during a five-year period.\n\neruptions.n_events(5).pmf(2)\n\n0.2704\n\n\n(c) Return the probability that at least three years pass after you have read this exercise before the next eruption.\n\neruptions.waiting_time().sf(3)\n\n0.2890"
  },
  {
    "objectID": "posts/20221105-py_advent_2020.html",
    "href": "posts/20221105-py_advent_2020.html",
    "title": "Advent of Code 2020",
    "section": "",
    "text": "These are my solutions to the Advent of Code 2020 in Python."
  },
  {
    "objectID": "posts/20221105-py_advent_2020.html#history",
    "href": "posts/20221105-py_advent_2020.html#history",
    "title": "Advent of Code 2020",
    "section": "History",
    "text": "History\n\n(2022-11-12) Initialised the notebook, collecting the first 6 days"
  },
  {
    "objectID": "posts/20221105-py_advent_2020.html#dependencies",
    "href": "posts/20221105-py_advent_2020.html#dependencies",
    "title": "Advent of Code 2020",
    "section": "Dependencies",
    "text": "Dependencies\n\nfrom __future__ import annotations\nimport itertools as it\nimport collections\nimport dataclasses\nimport math\nimport numpy as np\nfrom parse import parse\nimport lrdataio"
  },
  {
    "objectID": "posts/20221105-py_advent_2020.html#functions",
    "href": "posts/20221105-py_advent_2020.html#functions",
    "title": "Advent of Code 2020",
    "section": "Functions",
    "text": "Functions\nhead(a: list) -> list\n\ndef head(a): return a[:3]"
  },
  {
    "objectID": "posts/20221105-py_advent_2020.html#puzzles",
    "href": "posts/20221105-py_advent_2020.html#puzzles",
    "title": "Advent of Code 2020",
    "section": "Puzzles",
    "text": "Puzzles\n\nDay 1\n--- Report Repair ---\n\n\nLoad the input\ntest1 = ['1721', '979', '366', '299', '675', '1456']\ninput1 = lrdataio.cache_advent(2020, 1)\n\n\nPrepare the input.\n\nereport = [int(x) for x in input1]\nhead(ereport)\n\n[1287, 1366, 1669]\n\n\nn_sum(nums: ndarray, n: int, target: int) -> int\n\ndef n_sum(nums, size, target):\n    for comb in it.combinations(nums, size):\n        if sum(comb) == target:\n            return math.prod(comb)\n\n\nPart 1\nFind the two entries that sum to 2020; what do you get if you multiply them together?\nSolution =\n\nn_sum(ereport, 2, 2020)\n\n691771\n\n\n\n\nPart 2\nIn your expense report, what is the product of the three entries that sum to 2020?\nSolution =\n\nn_sum(ereport, 3, 2020)\n\n232508760\n\n\n\n\n\nDay 2\n--- Password Philosophy ---\n\n\nLoad the input\ntest2 = ['1-3 a: abcde',\n         '1-3 b: cdefg',\n         '2-9 c: ccccccccc']\ninput2 = lrdataio.cache_advent(2020, 2)\n\n\nPrepare the input.\n\npasswords = input2\nhead(passwords)\n\n['4-5 t: ftttttrvts', '7-8 k: kkkkkkkf', '4-6 k: gqjkkk']\n\n\nn_valid_passwords(passwords: ndarray, cond: Callable) -> int\n\ndef n_valid_passwords(passwords, cond) -> int:\n    return sum(cond(password) for password in passwords)\n\n\nPart 1\nHow many passwords are valid according to their policies?\nfirst_rule(s: str) -> bool\n\ndef first_rule(s: str) -> bool:\n    r = parse('{min:d}-{max:d} {ch}: {pw}', s)\n    k = collections.Counter(r['pw'])\n    return r['min'] <= k[r['ch']] <= r['max']\n\nSolution =\n\nn_valid_passwords(passwords, first_rule)\n\n560\n\n\n\n\nPart 2\nHow many passwords are valid according to the new interpretation of the policies?\nsecond_rule(s: str) -> bool\n\ndef second_rule(s: str) -> bool:\n    r = parse('{i:d}-{j:d} {c}: {pw}', s)\n    i, j, ch, pw = r['i']-1, r['j']-1, r['c'], r['pw']\n    return ((pw[i] == ch and pw[j] != ch)\n            or (pw[j] == ch and pw[i] != ch))\n\nSolution =\n\nn_valid_passwords(passwords, second_rule)\n\n303\n\n\n\n\n\nDay 3\n--- Toboggan Trajectory ---\n\n\nLoad the input\ntinput3 = ['..##.......',\n           '#...#...#..',\n           '.#....#..#.',\n           '..#.#...#.#',\n           '.#...##..#.',\n           '..#.##.....',\n           '.#.#.#....#',\n           '.#........#',\n           '#.##...#...',\n           '#...##....#',\n           '.#..#...#.#']\ninput3 = lrdataio.cache_advent(2020, 3)\n\n\nPrepare the input.\n\ntree_map = input3\nhead(tree_map)\n\n['.........#..##..#..#........#..',\n '#...#..#..#...##.....##.##.#...',\n '....#..............#....#....#.']\n\n\nn_tree_collisions(tm: list[list], di: int, dj: int) -> int:\n\ndef n_tree_collisions(tm, di, dj) -> int:\n    i, j, ii, jj = 0, 0, len(tm), len(tm[0])  # origin, boundary\n    n = 0\n    while i < ii:\n        n += (tm[i][j % jj] == '#')\n        i += di\n        j += dj\n\n    return n\n\n\nPart 1\nStarting at the top-left corner of your map and following a slope of right 3 and down 1, how many trees would you encounter?\nSolution =\n\nn_tree_collisions(tree_map, 1, 3)\n\n156\n\n\n\n\nPart 2\nWhat do you get if you multiply together the number of trees encountered on each of the listed slopes?\nSolution =\n\ndeltas = [[1, 1], [1, 3], [1, 5], [1, 7], [2, 1]]\nmath.prod(n_tree_collisions(tree_map, di, dj) for di, dj in deltas)\n\n3521829480\n\n\n\n\n\nDay 4\n--- Passport Processing ---\n\n\nLoad the input\ntinput4 = ['ecl:gry pid:860033327 eyr:2020 hcl:#fffffd',\n           'byr:1937 iyr:2017 cid:147 hgt:183cm',\n           '',\n           'iyr:2013 ecl:amb cid:350 eyr:2023 pid:028048884',\n           'hcl:#cfa07d byr:1929',\n           '',\n           'hcl:#ae17e1 iyr:2013',\n           'eyr:2024',\n           'ecl:brn pid:760753108 byr:1931',\n           'hgt:179cm',\n           '',\n           'hcl:#cfa07d eyr:2025 pid:166559648',\n           'iyr:2011 ecl:brn hgt:59in']\ninput4 = lrdataio.cache_advent(2020, 4)\n\n\nPrepare the input.\nparse_batch_file(bf: list[str]) -> list[str]\n\ndef parse_batch_file(data: list[str]) -> list[str]:\n    def replace_empty_str(s): return '\\n' if len(s) == 0 else s\n\n    joined_line = ' '.join([replace_empty_str(s) for s in data]).lstrip(' ')\n    return joined_line.split(' \\n ')\n\n\nparsed_bf = parse_batch_file(input4)\nhead(parsed_bf)\n\n['byr:1983 iyr:2017 pid:796082981 cid:129 eyr:2030 ecl:oth hgt:182cm',\n 'iyr:2019 cid:314 eyr:2039 hcl:#cfa07d hgt:171cm ecl:#0180ce byr:2006 pid:8204115568',\n 'byr:1991 eyr:2022 hcl:#341e13 iyr:2016 pid:729933757 hgt:167cm ecl:gry']\n\n\nScanner\nA class to model a passport scanner. Its interface is comprised of Boolean tests that checks each condition for a valid passport.\n\n\nShow class definition\n@dataclasses.dataclass\nclass Scanner:\n    byr: str  # Birth Year\n    iyr: str  # Issue Year\n    eyr: str  # Expiration Year\n    hgt: str  # Height\n    hcl: str  # Hair Color\n    ecl: str  # Eye Color\n    pid: str  # Passport ID\n    cid: str  # Country ID\n\n    @classmethod\n    def from_str(cls, s: str) -> Scanner:\n        seq = s.split(' ')\n        r = collections.defaultdict(lambda: '')\n        for item in seq:\n            k, v = item.split(':')\n            r[k] = v\n        ks = ['byr', 'iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n        return cls(*[r[k] for k in ks])\n\n    @staticmethod\n    def is_valid_year(y: str, lower: int, upper: int) -> bool:\n        return (len(y) == 4\n                and y.isnumeric()\n                and lower <= int(y) <= upper)\n\n    def __len__(self) -> int:\n        # return the number of completed required fields\n        return sum(1 if k != 'cid' and v != '' else 0\n                   for k, v in self.__dict__.items())\n\n    def has_valid_byr(self) -> bool:\n        return Scanner.is_valid_year(self.byr, 1920, 2002)\n\n    def has_valid_iyr(self) -> bool:\n        return Scanner.is_valid_year(self.iyr, 2010, 2020)\n\n    def has_valid_eyr(self) -> bool:\n        return Scanner.is_valid_year(self.eyr, 2020, 2030)\n\n    def has_valid_hgt(self) -> bool:\n        if len(self.hgt) <= 3:  # guard\n            return False\n        h, unit = self.hgt[:-2], self.hgt[-2:]\n        if h.isnumeric():\n            if unit == 'cm':\n                return 150 <= int(h) <= 193\n            elif unit == 'in':\n                return 59 <= int(h) <= 76\n            else:  # not a recognised unit\n                return False\n        return False\n\n    def has_valid_hcl(self) -> bool:\n        if self.hcl[0] != '#':  # guard\n            return False\n        try:\n            int(self.hcl[1:], base=16)\n        except ValueError:\n            return False\n        return True\n\n    def has_valid_ecl(self) -> bool:\n        return self.ecl in ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']\n\n    def has_valid_pid(self) -> bool:\n        try:\n            num = int(self.pid)\n        except ValueError:\n            return False\n        return str(num).rjust(9, '0') == self.pid\n\n    def passes_first_stage(self) -> bool:\n        # return true if all 7 required fields are complete\n        return len(self) == 7\n\n    def passes_second_stage(self) -> bool:\n        return all([self.has_valid_byr(),\n                    self.has_valid_iyr(),\n                    self.has_valid_eyr(),\n                    self.has_valid_hgt(),\n                    self.has_valid_hcl(),\n                    self.has_valid_ecl(),\n                    self.has_valid_pid()])\n\n    def passes_both_stages(self) -> bool:\n        return self.passes_first_stage() and self.passes_second_stage()\n\n\n\nPart 1\nCount the number of valid passports - those that have all required fields. Treat cid as optional. In your batch file, how many passports are valid?\nSolution =\n\nscanners = [Scanner.from_str(line) for line in parsed_bf]\nlen([scanner for scanner in scanners if scanner.passes_first_stage()])\n\n239\n\n\n\n\nPart 2\nCount the number of valid passports - those that have all required fields and valid values. Continue to treat cid as optional. In your batch file, how many passports are valid?\nSolution =\n\nscanners = [Scanner.from_str(line) for line in parsed_bf]\nlen([scanner for scanner in scanners if scanner.passes_both_stages()])\n\n188\n\n\n\n\n\nDay 5\n--- Binary Boarding ---\n\n\nLoad the input\ntinput5 = ['FBFBBFFRLR',\n           'BFFFBBFRRR',\n           'FFFBBBFRRR',\n           'BBFFBBFRLL']\ninput5 = lrdataio.cache_advent(2020, 5)\n\n\nPrepare the input.\nbin_str(s: str) -> str\n\ndef bin_str(s: str) -> str:\n    return ''.join(['1' if x in ['B', 'R'] else '0' for x in s])\n\nint_str(bin_str: str) -> int\n\ndef int_str(bin_str: str) -> int: return int(bin_str, 2)\n\n\nseat_ids = sorted([int_str(bin_str(s)) for s in input5])\nhead(seat_ids)\n\n[32, 33, 34]\n\n\n\nPart 1\nAs a sanity check, look through your list of boarding passes. What is the highest seat ID on a boarding pass?\nSolution =\n\nseat_ids[-1]\n\n848\n\n\n\n\nPart 2\nWhat is the ID of your seat?\n\ndef find_seat(seat_ids) -> int:\n    left, right = np.array(seat_ids[:-1]), np.array(seat_ids[1:])\n    for i, diff in enumerate(right - left):\n        if diff != 1:\n            return left[i] + 1\n\nSolution =\n\nfind_seat(seat_ids)\n\n682\n\n\n\n\n\nDay 6\n--- Custom Customs ---\n\n\nLoad the input\ntinput6 = ['abc', '', 'a', 'b', 'c', '', 'ab', 'ac', '', 'a', 'a', 'a', 'a', '', 'b']  # noqa\ninput6 = lrdataio.cache_advent(2020, 6)\n\n\nPrepare the input.\ngroup_party_answers(a: list[str]) -> list[list[str]]\n\ndef group_party_answers(a) -> list[list[str]]:\n    def replace_empty_str(s): return '\\n' if len(s) == 0 else s\n\n    joined = ' '.join([replace_empty_str(s) for s in a]).lstrip(' ')\n    groups = joined.split(' \\n ')\n    return [group.split(' ') for group in groups]\n\n\nparties_answers = group_party_answers(input6)\nhead(parties_answers)\n\n[['we', 'euw', 'we'],\n ['czaxvodqbsjeytwhurpg', 'gclajqykpmxfbohvtedzwrus'],\n ['dxoznjqhwuvblprgekyfcm', 'ghbozdkxqjevwfrypcnul', 'rxpjtgwvuoeqfhlkncdbyz']]\n\n\n\nPart 1\nFor each group, count the number of questions to which anyone answered “yes”. What is the sum of those counts?\nn_unique(party_answers: list[str]) -> int\n\ndef n_unique(party_answers: list[str]) -> int:\n    return len(set(''.join(party_answers)))\n\nSolution =\n\nsum(n_unique(party_answers) for party_answers in parties_answers)\n\n6763\n\n\n\n\nPart 2\nFor each group, count the number of questions to which everyone answered “yes”. What is the sum of those counts?\nn_all_yes(party_answers: list[str]) -> int\n\ndef n_all_yes(party_answers: list[str]) -> int:\n    n = len(party_answers)\n    q_counter = collections.Counter(''.join(party_answers))\n    return len([*filter(lambda q: q_counter[q] == n, q_counter.keys())])\n\nSolution =\n\nsum([n_all_yes(party_answers) for party_answers in parties_answers])\n\n3512"
  },
  {
    "objectID": "posts/20221106-m343_b2p2_poisson_processes.html",
    "href": "posts/20221106-m343_b2p2_poisson_processes.html",
    "title": "Modelling Events In Time",
    "section": "",
    "text": "This notebook covers M343 Book 2, Part 2: Modelling events in time."
  },
  {
    "objectID": "posts/20221106-m343_b2p2_poisson_processes.html#functions",
    "href": "posts/20221106-m343_b2p2_poisson_processes.html#functions",
    "title": "Modelling Events In Time",
    "section": "Functions",
    "text": "Functions\nConvencience function for plotting the models.\nplot_n_events(ne: rv_discrete, step: int = 1) -> so.Plot\n\n\nCode\ndef plot_n_events(nt, step=1) -> so.Plot:\n    \"\"\"Plot the approximated probability distribution of N(t),\n    the number of events in time.\n\n    Pass step to reduce the number of events plotted, if the returned\n    plot is cluttered.\n    \"\"\"\n    ns = np.arange(nt.ppf(0.01), nt.ppf(0.99), dtype=int, step=step)\n    return (\n        so.Plot(x=ns, y=nt.pmf(ns))\n        .add(so.Bar())\n        .label(x='n', y='p(n)', title='Probability distribution')\n    )\n\n\nplot_waiting_time(wt: rv_continuous) -> so.Plot\n\n\nCode\ndef plot_waiting_time(wt) -> so.Plot:\n    \"\"\"Plot the approximate probability distribution of T, the waiting\n    time between events.\n    \"\"\"\n    ts = np.linspace(wt.ppf(0.01), wt.ppf(0.99), num=50)\n    return(\n        so.Plot(x=ts, y=wt.pdf(ts))\n        .add(so.Line())\n        .label(x='t', y='f(t)', title='Probability distribution')\n    )"
  },
  {
    "objectID": "posts/20221106-m343_b2p2_poisson_processes.html#the-poisson-process",
    "href": "posts/20221106-m343_b2p2_poisson_processes.html#the-poisson-process",
    "title": "Modelling Events In Time",
    "section": "The Poisson process",
    "text": "The Poisson process\n\n1. Nerve impulses\nM343 Book 2, Activity 3.1\nInitialise impulses, Events, a Poisson process model for the occurrence of nerve impulses.\n\nimpulses = pp.Events(458)  # per second\nprint(impulses)\n\nEvents(rate=458)\n\n\nPlot the models for \\(N(t)\\), the number of events in time, and \\(T\\), the time between events.\n\nplot_n_events(impulses.n_events(), step=4)\n\n\n\n\n\nplot_waiting_time(impulses.waiting_time())\n\n\n\n\n(a) Return the probability that not more than one nerve impulse occurs in an interval of 1/100 second.\n\nimpulses.n_events(0.01).cdf(1)\n\n0.0572\n\n\n(b) Return the probability that the interval between two successive impulses is less than 1/1000 second.\n\nimpulses.waiting_time().cdf(0.001)\n\n0.3675\n\n\n\n\n2. Major earthquakes\nM343 Book 2, Activity 3.2\nInitialise earthquakes, Events, a Poisson process model for the incidence of major earthquakes worldwide.\n\nearthquakes = pp.Events(12/14)  # per year\n\nPlot the probability distribution for the number of earthquakes expected in 10 years.\n\nplot_n_events(earthquakes.n_events(10))\n\n\n\n\n\nplot_waiting_time(earthquakes.waiting_time())\n\n\n\n\n(a) Return the probability that there will be at least three major earthquakes in a period of ten years.\n\nearthquakes.n_events(1).sf(2)\n\n0.0560\n\n\n(b) Return the probability that the waiting time between successive major earthquakes exceeds two years.\n\nearthquakes.waiting_time().sf(0.001)\n\n0.9991"
  },
  {
    "objectID": "posts/20221106-m343_b2p2_poisson_processes.html#multivariate-poisson-process",
    "href": "posts/20221106-m343_b2p2_poisson_processes.html#multivariate-poisson-process",
    "title": "Modelling Events In Time",
    "section": "Multivariate Poisson process",
    "text": "Multivariate Poisson process\n\n1. Telephone calls\nM343 Book 2, Activity 5.2\nInitialise caller_rates, dict, a dictionary that maps the different kinds of people who call the tutor during the evening to their expected hourly rate.\n\ncaller_rates = {'student': 2/3,\n                'family': 1/3,\n                'friend': 1}\n\nInitialise phone_calls, MultivariateEvents, a multivariate Poisson process that models the arrival rate of the different kinds of call over the course of an evening.\n\nphone_calls = pp.MultivariateEvents(caller_rates)\n\n(a) Return probability that between 7pm and 9pm tomorrow evening, the tutor’s telephone will not ring.\n\nphone_calls[:].n_events(2).pmf(0)\n\n0.0183\n\n\n(b) Return the probability that the first call after 9pm is from a student.\n\nphone_calls.props['student']\n\n0.3333\n\n\n(c) Return the probability that exactly two of the calls are from members of her family, given that the tutor receives four telephone calls one evening.\n\nphone_calls.n_kind(4, 'family').pmf(2)\n\n0.1157\n\n\n(side question) If one evening the tutor receives 18 calls, plot the the distribution of the number of calls expected to be the tutor’s family.\n\nn_family = phone_calls.n_kind(18, 'family')\n_xs = np.arange(n_family.ppf(0.01), n_family.ppf(0.99), dtype=int)\n(\n    so.Plot(x=_xs, y=n_family.pmf(_xs))\n    .add(so.Bar())\n    .label(title='Probability distribution',\n           x='N',\n           y='p(n)')\n)\n\n\n\n\n\n\n2. Bank customers\nM343 Book 2, Activity 5.1\nInitialise bank_customers_props, dict, a dictionary that maps a kind of customer that uses the bank to their proportion of all kind of customers.\n\nbank_customer_props = {'A': 0.6, 'B': 0.3, 'C': 0.1}\n\nInitialise bank_customers, MultivariateEvents, a multivariate Poisson process that models the arrival of the different kinds of customers at the bank over the course of one minute.\n\nbank_customers = (\n    pp.MultivariateEvents\n    .from_props(bank_customer_props, aggregated_rate=10)\n)\n\n(a) Return the probability that more than five customers arrive in an interval of length 30 seconds.\n\nbank_customers[:].n_events(0.5).sf(5)\n\n0.3840\n\n\n(b) Return the probability that six customers of type A arrive in one minute.\n\nbank_customers['A'].n_events(1).pmf(6)\n\n0.1606\n\n\n(c) Return the probability that six customers of type A, three of type B and at least one of type C arrive in one minute.\n\nnp.prod([bank_customers['A'].n_events(1).pmf(6),\n         bank_customers['B'].n_events(1).pmf(3),\n         bank_customers['C'].n_events(1).sf(0)])\n\n0.0227\n\n\n\n\n3. Post office customers\nM343 Book 2, Exercise 5.1\nInitialise po_customer_props, dict, a dictionary that maps a kind of customer that uses the post office to their proportion of all kind of customers.\n\npo_customer_props = {'letters': 0.7,\n                     'parcels': 0.05,\n                     'other': 0.25}\n\nInitialise post_office, MultivariateEvents, a multivariate Poisson process that models the arrival of different kinds of customers at the post office over the course of an hour.\n\npost_office = pp.MultivariateEvents.from_props(po_customer_props, 8)\n\n(a) Return the rate at which customers arrive at the post office to post parcels.\n\npost_office.rates['parcels']\n\n0.4000\n\n\n(b) Return the probability that the interval between successive customers arriving to post parcels is greater than an hour.\n\npost_office['parcels'].waiting_time().sf(1)\n\n0.6703\n\n\n(c) Return the probability that over a three-hour period, fewer than five customers arrive to post letters.\n\npost_office['letters'].n_events(3).cdf(4)\n\n0.0002\n\n\nReturn the median waiting time between customers arriving to post something (either a letter or a parcel).\n\npost_office['letters', 'parcels'].waiting_time().median()\n\n0.1155\n\n\n\n\n4. Library acquisitions\nM343 Book 2, Exercise 5.2\nInitialise book_arrival_rates, dict, a dictionary that maps a kind of book that is acquired by library to their acquisition rates over a week.\n\nbook_arrival_rates = {'fiction': 8,\n                      'biographies': 1,\n                      'reference': 0.25,\n                      'non-text': 5}\n\nInitialise book_arrivals, MultivariateEvents, a multivariate Poisson process that models the arrival of the different kinds of books at the library over the course of a week.\n\nbook_arrivals = pp.MultivariateEvents(book_arrival_rates)\n\n(a) Return the probability that at least two non-text acquisitions will arrive next week.\n\nbook_arrivals['non-text'].n_events(1).sf(1)\n\n0.9596\n\n\n(b) Return the probability that no new work of fiction will arrive tomorrow.\n\nbook_arrivals['fiction'].n_events(1/7).pmf(0)\n\n0.3189\n\n\n(c) Output the proportion of each new acquisition type.\n\nbook_arrivals.describe()\n\n\n\n\n\n  \n    \n      \n      rate\n      prop\n    \n    \n      kind\n      \n      \n    \n  \n  \n    \n      fiction\n      8.00\n      0.561404\n    \n    \n      biographies\n      1.00\n      0.070175\n    \n    \n      reference\n      0.25\n      0.017544\n    \n    \n      non-text\n      5.00\n      0.350877"
  },
  {
    "objectID": "posts/20221106-m343_b2p2_poisson_processes.html#non-homogeneous-poisson-process",
    "href": "posts/20221106-m343_b2p2_poisson_processes.html#non-homogeneous-poisson-process",
    "title": "Modelling Events In Time",
    "section": "Non-homogeneous Poisson process",
    "text": "Non-homogeneous Poisson process\n\n1. Errors in a maze\nM343 Book 2, Example 5.1\nDefine the maze_error_rate, a function that describes the number of errors made by a rat learning its way around a maze in relation to time spent learning.\n\ndef maze_error_rate(t): return 8 * np.exp(-t)  # t >= 0\n\nInitialise learning_rat, NonHomogenousEvents, a non-homogenous Poisson process that models the occurrence of errors by rats learning their way around a maze over time.\n\nlearning_rat = pp.NonHomogenousEvents(maze_error_rate)\n\nPlot the interval rate between t = (0, 4).\n\nts = np.linspace(0, 4)\nrs = np.array([learning_rat.rate(t) for t in ts])\n(\n    so.Plot(x=ts, y=rs)\n    .add(so.Line())\n    .label(x='t', y='rate(t)')\n)\n\n\n\n\nReturn the probability that the number of errors made by a rat in the second hour is more that two.\n\nlearning_rat.n_events(1, 2).sf(2)\n\n0.2856\n\n\n\n\n2. Learning to ride\nM343 Book 2, Activity 6.2\nDefine bike_accident rate, a function that returns the rate of accidents made by a child learning to ride a bike at time t.\n\ndef bike_accident_rate(t): return 24 / (2 + t)  # t >= 0\n\nInitialise bike_accidents, NonHomogenousEvents, a non-homogenous Poisson process that models the occurrence of bike accidents by a child over time.\n\nbike_accidents = pp.NonHomogenousEvents(bike_accident_rate)\n\n(a) Return the expected number of accidents during the first week.\n\nbike_accidents.n_events(0, 7).mean()\n\n36.0979\n\n\n(b.i) Return the expected number of accidents in the third week.\n\nbike_accidents.n_events(14, 21).mean()\n\n8.7097\n\n\n(b.ii) Return the probability that the girl has eight accidents in the third week.\n\nbike_accidents.n_events(14, 21).pmf(8)\n\n0.1355\n\n\n(c) Return the probability that the fourth week is free of accidents.\n\nbike_accidents.n_events(21, 28).pmf(0)\n\n0.0017\n\n\n\n\n3. Event times\nM343 Book 2, Exercise 6.1\nDefine some_error_rate, a function that returns the expected error rate at time t.\n\ndef some_error_rate(t): return (3/8) * (t ** 2) * (4 - t)  # 0 <= t <= 4\n\nInitialise some_events, NonHomogenousEvents, a representation of the non-homogenous Poisson process that models the occurrence of errors at rate some_error_rate.\n\nsome_events = pp.NonHomogenousEvents(some_error_rate)\n\n(c) Return the expected number of errors between t = (1, 3).\n\nsome_events.n_events(1, 3).mean()\n\n5.5000\n\n\n(d) Return the probability that more than two errors occur between t = (1, 3).\n\nsome_events.n_events(1, 3).sf(2)\n\n0.9116\n\n\n(e) Given that two errors occur between t = (0, 1), return the probability that at least four errors occur in total (that is, between t = (0, 4)).\n\nsome_events.n_events(1, 4).sf(1)\n\n0.9957"
  },
  {
    "objectID": "posts/20221106-poissonprocesses.html",
    "href": "posts/20221106-poissonprocesses.html",
    "title": "PoissonProcesses",
    "section": "",
    "text": "Load the dependencies"
  },
  {
    "objectID": "posts/20221106-poissonprocesses.html#events",
    "href": "posts/20221106-poissonprocesses.html#events",
    "title": "PoissonProcesses",
    "section": "Events",
    "text": "Events\nA class that models a single Poisson process.\nrate : float, int\nRate of occurrence of an event is unit time.\n\nn_events(t: float, int) -> rv_discrete\nReturn the model for the number of events that occur in t units of time.\nThis is modelled \\(N(t) \\sim\\) Poisson(\\(\\lambda t\\)), where \\(\\lambda\\) = self.rate.\n\n\nwaiting_time() -> rv_continuous\nReturn a model for the time between successive events.\nThis is the model \\(T \\sim M(\\lambda)\\), where \\(\\lambda\\) = self.rate.\n\n\nExample use\nAssume that patients arrive at a hospital at a rate of 6/hour.\nInitialise the model.\n\nhospital_arrivals = pp.Events(6)  # per hour\nprint(hospital_arrivals)\n\nEvents(rate=6)\n\n\nWe can return the model the number of events in unit time (i.e., one hour) by calling n_events().\nReturn the probability that no patients arrive at the hospital in a one hour window.\n\nhospital_arrivals.n_events().pmf(0)\n\n0.0025\n\n\nPass an argument if you want to rescale the window. For example, passing t=0.5 will return the model for the number of events that occur in 0.5 hour (or 30 minutes).\nCalculate the probability that two patients arrive in 30 minutes.\n\nhospital_arrivals.n_events(0.5).pmf(2)\n\n0.2240\n\n\nCalling the waiting_time() method will return the model for the time between successive events.\nWhat is the probability that the interval between arrivals exceeds 30 minutes?\n\nhospital_arrivals.waiting_time().sf(0.5)\n\n0.0498"
  },
  {
    "objectID": "posts/20221106-poissonprocesses.html#multivariateevents",
    "href": "posts/20221106-poissonprocesses.html#multivariateevents",
    "title": "PoissonProcesses",
    "section": "MultivariateEvents",
    "text": "MultivariateEvents\nA class that models a multivariate Poisson process.\nrates : dict\nA dict that maps a kind of event to its rate of occurrence.\naggregated_rate : float, int (Property)\nThe aggregated rate of occurrence for all kinds of event.\nprops : dict (Property)\nA dict that maps a kind of event to its proportion of all kinds of events.\n@classmethod\nfrom_props(props: dict, aggregated_rate: float | int) -> MultivariateEvents\nInitialise and return an instance of MultivariateEvents using proportions rather than rates. Argument aggregated rate should be the combined rate of all kinds of event.\nPrecondtions\n\nsum(values(props)) = 1\n0 < prop <= 1 for each prop in values(props)\naggregated_rate > 0\n\nn_kind(n_star: int, kind: object) -> rv_discrete\nReturn a model for the number of events of the given kind, given n_star events took place.\nThis is the model N ~ B(n_star, self.props[kind]. This is modelled \\(N \\sim B\\)(n_star, \\(p\\)), where \\(p\\) = self.props[kind].\n\nExample use\nThe different types of call to a mobile phone company’s call centre can be modelled as independent Poisson processes. Calls from customers that wish to cancel their subscription occur at a rate of 20 per hour. Calls from customers who wish to make a complaints occur at a rate of 35 per hour. And calls from customers who wish to subscribe to the service occur at a rate of 22 per hour.\nInitialise the model.\n\ncall_rates = {'cancel': 20,\n              'complain': 35,\n              'new': 22}\ncall_centre = pp.MultivariateEvents(call_rates)  # per hour\n\nThe different models can be accessed by indexing. This returns a instance of Event.\nReturn the probability that 30 customers call to cancel their subscription over the course of 90 minutes.\n\ncall_centre['cancel'].n_events(1.5).pmf(30)\n\n0.0726\n\n\nModels can be combined by listing the different kinds of events.\nWhat is the expected time between customers wishing to cancel or complain about the service?\n\ncall_centre['cancel', 'complain'].waiting_time().mean()\n\n0.0182\n\n\nThe aggregated model that describes all events can be accessed by either passing : or ... as an index.\nWhat is the probability that less that 60 customers call in one hour?\n\ncall_centre[:].n_events().cdf(59)\n\n0.0198\n\n\nWhat is the probability that 15 customers called to cancel their account, given 40 customers called?\nNote, this returns frozen instance of scipy.stats.binom.\n\ncall_centre.n_kind(40, 'cancel').pmf(15)\n\n0.0361\n\n\nAnimals pass by a person’s window according to a Poisson process at a rate of 20 animals per hour. Of those animals, approximately 60% are birds, 30% are cats, and 10% are dogs.\nInitialise the model.\n\nprops = {'birds': 0.6,\n         'cats': 0.3,\n         'dogs': 0.1}\npassing_animals = pp.MultivariateEvents.from_props(props, 20)"
  },
  {
    "objectID": "posts/20221106-poissonprocesses.html#functions",
    "href": "posts/20221106-poissonprocesses.html#functions",
    "title": "PoissonProcesses",
    "section": "Functions",
    "text": "Functions\nget_cont_xs(rv: rv_continuous) -> so.Plot\n\ndef get_cont_xs(rv):\n    return np.linspace(rv.ppf(0.01), rv.ppf(0.99), num=50)\n\nget_disc_xs(rv: rv_discrete, step: int = 1) -> so.Plot\n\ndef get_disc_xs(rv, step=1):\n    return np.arange(rv.ppf(0.01), rv.ppf(0.99), dtype=int, step=step)\n\nplot_n_events(ne: rv_discrete, step: int = 1) -> so.Plot\n\ndef plot_n_events(nt, step = 1) -> so.Plot:\n    \"\"\"Plot the approximated probability distribution of N(t),\n    the number of events in time.\n\n    Pass step to reduce the number of events plotted, if the returned\n    plot is cluttered.\n    \"\"\"\n    ns = get_disc_xs(nt, step)\n    return (\n        so.Plot(x=ns, y=nt.pmf(ns))\n        .add(so.Bar())\n        .label(x='n', y='p(n)', title='Probability distribution')\n    )\n\nplot_waiting_time(wt: rv_continuous) -> so.Plot\n\ndef plot_waiting_time(wt) -> so.Plot:\n    \"\"\"Plot the approximate probability distribution of T, the waiting\n    time between events.\n    \"\"\"\n    ts = get_cont_xs(wt)\n    return(\n        so.Plot(x=ts, y=wt.pdf(ts))\n        .add(so.Line())\n        .label(x='t', y='f(t)', title='Probability distribution')\n    )"
  },
  {
    "objectID": "posts/20221106-poissonprocesses.html#the-poisson-process",
    "href": "posts/20221106-poissonprocesses.html#the-poisson-process",
    "title": "PoissonProcesses",
    "section": "The Poisson process",
    "text": "The Poisson process\n\n1. Nerve impulses\nM343 Book 2, Activity 3.1\nInitialise impulses, Event, a Poisson process model for the incidence of impulses.\n\nimpulses = pp.Events(458)  # per second\nprint(impulses)\n\nEvents(rate=458)\n\n\nPlot the models for \\(N(t)\\), the number of events in time, and \\(T\\), the time between events.\n\nplot_n_events(impulses.n_events(), step=4)\n\n\n\n\n\nplot_waiting_time(impulses.waiting_time())\n\n\n\n\n(a) Return the probability that not more than one nerve impulse occurs in an interval of 1/100 second.\n\nimpulses.n_events(0.01).cdf(1)\n\n0.0572\n\n\n(b) Return the probability that the interval between two successive impulses is less than 1/1000 second.\n\nimpulses.waiting_time().cdf(0.001)\n\n0.3675\n\n\n\n\n2. Major earthquakes\nM343 Book 2, Activity 3.2\nInitialise earthquakes, Event, a Poisson process model for the incidence of major earthquakes worldwide.\n\nearthquakes = pp.Events(12/14)  # per year\n\nPlot the probability distribution for the number of earthquakes expected in 10 years.\n\nplot_n_events(earthquakes.n_events(10))\n\n\n\n\n\nplot_waiting_time(earthquakes.waiting_time())\n\n\n\n\n(a) Return the probability that there will be at least three major earthquakes in a period of ten years.\n\nearthquakes.n_events(1).sf(2)\n\n0.0560\n\n\n(b) Return the probability that the waiting time between successive major earthquakes exceeds two years.\n\nearthquakes.waiting_time().sf(0.001)\n\n0.9991"
  },
  {
    "objectID": "posts/20221106-poissonprocesses.html#multivariate-poisson-processes",
    "href": "posts/20221106-poissonprocesses.html#multivariate-poisson-processes",
    "title": "PoissonProcesses",
    "section": "Multivariate Poisson processes",
    "text": "Multivariate Poisson processes\n\n1. Telephone calls\nM343 Book 2, Activity 5.2\nInitialise caller_rates, dict, a dictionary that maps the different kinds of people who call the tutor during the evening to their expected hourly rate.\n\ncaller_rates = {'student': 2/3,\n                'family': 1/3,\n                'friend': 1}\n\nInitialise phone_calls, MultivariateEvents, a multivariate Poisson process that models the arrival rate of the different kinds of call over the course of an evening.\n\nphone_calls = pp.MultivariateEvents(caller_rates)\n\n(a) Return probability that between 7pm and 9pm tomorrow evening, the tutor’s telephone will not ring.\n\nphone_calls[:].n_events(2).pmf(0)\n\n0.0183\n\n\n(b) Return the probability that the first call after 9pm is from a student.\n\nphone_calls.props['student']\n\n0.3333\n\n\n(c) Return the probability that exactly two of the calls are from members of her family, given that the tutor receives four telephone calls one evening.\n\nphone_calls.n_kind(4, 'family').pmf(2)\n\n0.1157\n\n\n(side question) If one evening the tutor receives 18 calls, plot the the distribution of the number of calls expected to be the tutor’s family.\n\nn_family = phone_calls.n_kind(18, 'family')\n_xs = np.arange(n_family.ppf(0.01), n_family.ppf(0.99), dtype=int)\n(\n    so.Plot(x=_xs, y=n_family.pmf(_xs))\n    .add(so.Bar())\n    .label(title='Probability distribution',\n           x='N',\n           y='p(n)')\n)\n\n\n\n\n\n\n2. Bank customers\nM343 Book 2, Activity 5.1\nInitialise bank_customers_props, dict, a dictionary that maps a kind of customer that uses the bank to their proportion of all kind of customers.\n\nbank_customer_props = {'A': 0.6, 'B': 0.3, 'C': 0.1}\n\nInitialise bank_customers, Multivariate, a rmultivariate Poisson process that models the arrival of the different kinds of customers at the bank over the course of one minute.\n\nbank_customers = (\n    pp.MultivariateEvents\n    .from_props(bank_customer_props, aggregated_rate=10)\n)\n\nPlot the models.\n\n# gather pmfs\n(\n    \n)\npd.DataFrame()\n\n\n\n\n\n  \n    \n      \n    \n  \n  \n  \n\n\n\n\n(a) Return the probability that more than five customers arrive in an interval of length 30 seconds.\n\nbank_customers[:].n_events(0.5).sf(5)\n\n0.3840\n\n\n(b) Return the probability that six customers of type A arrive in one minute.\n\nbank_customers['A'].n_events(1).pmf(6)\n\n0.1606\n\n\n(c) Return the probability that six customers of type A, three of type B and at least one of type C arrive in one minute.\n\nnp.prod([bank_customers['A'](1).pmf(6),\n         bank_customers['B'](1).pmf(3),\n         bank_customers['C'](1).sf(0)])\n\nTypeError: 'Events' object is not callable\n\n\n\n\n3. Post office customers\nM343 Book 2, Exercise 5.1\nInitialise po_customer_props, dict, a dictionary that maps a kind of customer that uses the post office to their proportion of all kind of customers.\n\npo_customer_props = {'letters': 0.7,\n                     'parcels': 0.05,\n                     'other': 0.25}\n\nInitialise post_office, Multivariate, a multivariate Poisson process that models the arrival of different kinds of customers at the post office over the course of an hour.\n\npost_office = pp.Multivariate.from_props(po_customer_props, aggregated_rate=8)\n\n(a) Return the rate at which customers arrive at the post office to post parcels.\n\npost_office.rates['parcels']\n\n(b) Return the probability that the interval between successive customers arriving to post parcels is greater than an hour.\n\npost_office['parcels'].waiting_time().sf(1)\n\n(c) Return the probability that over a three-hour period, fewer than five customers arrive to post letters.\n\npost_office['letters'].n_events(3).cdf(4)\n\nReturn the median waiting time between customers arriving to post something (either a letter or a parcel).\n\npost_office['letters', 'parcels'].waiting_time().median()\n\n\n\n4. Library acquisitions\nM343 Book 2, Exercise 5.2\nInitialise book_arrival_rates, dict, a dictionary that maps a kind of book that is acquired by library to their acquisition rates over a week.\n\nbook_arrival_rates = {'fiction': 8,\n                      'biographies': 1,\n                      'reference': 0.25,\n                      'non-text': 5}\n\nInitialise book_arrivals, Multivariate, a multivariate Poisson process that models the arrival of the different kinds of books at the library over the course of a week.\n\nbook_arrivals = Multivariate(book_arrival_rates)\n\n(a) Return the probability that at least two non-text acquisitions will arrive next week.\n\nbook_arrivals['non-text'].n_events(1).sf(1)\n\n(b) Return the probability that no new work of fiction will arrive tomorrow.\n\nbook_arrivals['fiction'].n_events(1/7).pmf(0)\n\n(c) Output the proportion of each new acquisition type.\n\nbook_arrivals.describe()"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html",
    "href": "posts/20221107-tt_incarceration_trends.html",
    "title": "Incarceration Trends",
    "section": "",
    "text": "#tidytuesday | Incarceration trends | source"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html#dependencies",
    "href": "posts/20221107-tt_incarceration_trends.html#dependencies",
    "title": "Incarceration Trends",
    "section": "Dependencies",
    "text": "Dependencies\n\n\nShow the code\nfrom collections import Counter\nimport pandas as pd\nfrom parse import parse\nimport seaborn as sns\nfrom seaborn import objects as so\nfrom matplotlib import style\nimport lrdataio\n\n\n\n\nShow the code\n%load_ext watermark\n%watermark -iv\n\n\nmatplotlib: 3.6.0\nlrdataio  : 0.3.0\nseaborn   : 0.12.1\npandas    : 1.4.4"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html#dataio",
    "href": "posts/20221107-tt_incarceration_trends.html#dataio",
    "title": "Incarceration Trends",
    "section": "DataIO",
    "text": "DataIO\nsource_df\n\n\nShow the code\n#source_url = 'https://raw.githubusercontent.com/vera-institute/incarceration-trends/master/incarceration_trends.csv'  # noqa\nsource_url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/incarceration_trends.csv'  # noqa\nsource_df = pd.read_csv(lrdataio.cache_url(source_url))\n\n\nfips_df\n\n\nShow the code\nfips_url = 'https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/fips/fips_table.csv'  # noqa\nfips_df = pd.read_csv(lrdataio.cache_url(fips_url), encoding='cp1252')"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html#views",
    "href": "posts/20221107-tt_incarceration_trends.html#views",
    "title": "Incarceration Trends",
    "section": "Views",
    "text": "Views\nv_source() -> pd.DataFrame\n\n\nShow the code\ndef v_source() -> pd.DataFrame:\n    return (\n        source_df\n        .rename(columns={'yfips': 'id', 'fips': 'county_id'})\n        .set_index(['county_id', 'year'])\n    )\n\n\nv_county() -> pd.DataFrame\n\n\nShow the code\ndef v_county() -> pd.DataFrame:\n    return (\n        fips_df\n        .merge(\n            right=source_df[['fips',\n                             'capacity',\n                             'commuting_zone',\n                             'land_area',\n                             'metro_area',\n                             'num_employees',\n                             'urbanicity']],\n            left_on='county_id',\n            right_on='fips'\n        )\n        .drop_duplicates()\n        .drop(columns='fips')\n        .reset_index(drop=True)\n    )\n\n\nv_crime() -> pd.DataFrame\n\n\nShow the code\ndef v_crime() -> pd.DataFrame:\n    selected_cols = (['county_id', 'year']\n                     + [c for c in v_source().columns if '_crime' in c])\n    return (\n        v_source()[selected_cols]\n        .dropna(how='all', subset=selected_cols[2:])\n        .rename(columns={c: c.replace('_crime', '') for c in selected_cols})\n        .rename(columns={'index': 'crime_index'})\n    )\n\n\nv_pop() -> pd.DataFrame()\n\n\nShow the code\ndef v_pop() -> pd.DataFrame:\n    return (\n        mv_pcp\n        # SELECT ONE OF THE VARIABLES\n        .query('variable == \"ethnicity\"')\n        .groupby(['county_id', 'year', 'area'])[['value']].sum()\n        .reset_index()\n    )\n\n\nmv_pcpop\n\n\nShow the code\ndef _parse_variable(s):\n    ls = s.split('_')\n    if ls[1] == 'pop':\n        ls[1] = 'county'\n    if ls[0] in ['male', 'female']:\n        ls.append('gender')\n    else:\n        ls.append('ethnicity')\n    return ls[1], ls[-1], ls[0]\n\n\nselected_cols = [c for c in v_source().columns\n                 if ('pop' in c\n                     and not ('_adm' in c\n                              or '_dcrp' in c\n                              or 'total_' in c\n                              or 'jail' in c\n                              or Counter(c)['_'] == 1))]\nmapper = {sc: _parse_variable(sc) for sc in selected_cols}\n\nmv_pcp = (\n    v_source()\n    .query('year >= 1990')\n    [[*mapper.keys()]]\n    .melt(var_name='col', ignore_index=False)\n    .dropna(subset='value')\n    .assign(\n        area=lambda x: x['col'].apply(lambda s: mapper[s][0]),\n        variable=lambda x: x['col'].apply(lambda s: mapper[s][1]),\n        group=lambda x: x['col'].apply(lambda s: mapper[s][2]),\n        value=lambda x: x['value'].mul(0.001)\n    )\n    .sort_values(by=['area', 'variable', 'group'])\n    [['area', 'variable', 'group', 'value']]\n    .reset_index()\n)\n\n\n\n\n\n\n  \n    \n      \n      county_id\n      year\n      area\n      variable\n      group\n      value\n    \n  \n  \n    \n      0\n      1001\n      1990\n      county\n      ethnicity\n      asian\n      0.096\n    \n    \n      1\n      1001\n      1991\n      county\n      ethnicity\n      asian\n      0.102\n    \n    \n      2\n      1001\n      1992\n      county\n      ethnicity\n      asian\n      0.111\n    \n    \n      3\n      1001\n      1993\n      county\n      ethnicity\n      asian\n      0.120\n    \n    \n      4\n      1001\n      1994\n      county\n      ethnicity\n      asian\n      0.126\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1026201\n      56041\n      2014\n      prison\n      gender\n      male\n      0.031\n    \n    \n      1026202\n      56043\n      2005\n      prison\n      gender\n      male\n      0.010\n    \n    \n      1026203\n      56043\n      2006\n      prison\n      gender\n      male\n      0.010\n    \n    \n      1026204\n      56043\n      2007\n      prison\n      gender\n      male\n      0.010\n    \n    \n      1026205\n      56043\n      2008\n      prison\n      gender\n      male\n      0.011\n    \n  \n\n1026206 rows × 6 columns\n\n\n\nv_county_pop() -> pd.DataFrame\n\n\nShow the code\ndef v_county_pop() -> pd.DataFrame:\n    return (\n        mv_pcp\n        .query('area == \"county\"')\n        .drop(columns='area')\n    )\n\n\nv_prison_pop() -> pd.DataFrame\n\n\nShow the code\ndef v_prison_pop() -> pd.DataFrame:\n    return (\n        mv_pcp\n        .query('area == \"prison\"')\n        .drop(columns='area')\n    )"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html#visualisations",
    "href": "posts/20221107-tt_incarceration_trends.html#visualisations",
    "title": "Incarceration Trends",
    "section": "Visualisations",
    "text": "Visualisations\n\nLongitudinal\nWe start by visualising the changes in different types of populations over time.\n\nPrison population change against that of the country\n\n\nShow the code\ndef _plot(df) -> so.Plot:\n    return (\n        so.Plot(df, x='year', y='value', color='area')\n        .add(so.Line())\n        .theme({**style.library[\"fivethirtyeight\"]})\n    )\n\n\n(\n    v_pop()\n    .groupby(['year', 'area'])[['value']].sum()\n    .groupby('area')[['value']].pct_change()\n    .pipe(_plot)\n)"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html#schemas",
    "href": "posts/20221107-tt_incarceration_trends.html#schemas",
    "title": "Incarceration Trends",
    "section": "Schemas",
    "text": "Schemas\n\n\nShow the code\nv_source().columns.sort_values().to_list()\n\n\n['agr_assault_crime',\n 'arson_crime',\n 'asian_jail_pop',\n 'asian_pop_15to64',\n 'asian_prison_adm',\n 'asian_prison_pop',\n 'black_jail_pop',\n 'black_pop_15to64',\n 'black_prison_adm',\n 'black_prison_pop',\n 'burglary_crime',\n 'capacity',\n 'commuting_zone',\n 'confined_pop',\n 'county_name',\n 'division',\n 'female_jail_adm_dcrp',\n 'female_jail_pop',\n 'female_jail_pop_dcrp',\n 'female_jail_pretrial',\n 'female_pop_15to64',\n 'female_prison_adm',\n 'female_prison_pop',\n 'id',\n 'index_crime',\n 'jail_from_fed',\n 'jail_from_ice',\n 'jail_from_other_state_jail',\n 'jail_from_other_state_prison',\n 'jail_from_state_jail',\n 'jail_from_state_prison',\n 'land_area',\n 'larceny_crime',\n 'latino_jail_pop',\n 'latino_pop_15to64',\n 'latino_prison_adm',\n 'latino_prison_pop',\n 'male_jail_adm_dcrp',\n 'male_jail_pop',\n 'male_jail_pop_dcrp',\n 'male_jail_pretrial',\n 'male_pop_15to64',\n 'male_prison_adm',\n 'male_prison_pop',\n 'metro_area',\n 'murder_crime',\n 'mv_theft_crime',\n 'native_jail_pop',\n 'native_pop_15to64',\n 'native_prison_adm',\n 'native_prison_pop',\n 'num_employees',\n 'num_facilites',\n 'other_pop_15to64',\n 'other_prison_adm',\n 'other_prison_pop',\n 'property_crime',\n 'rape_crime',\n 'region',\n 'robbery_crime',\n 'state',\n 'total_jail_adm',\n 'total_jail_adm_dcrp',\n 'total_jail_pop',\n 'total_jail_pop_dcrp',\n 'total_jail_pretrial',\n 'total_pop',\n 'total_pop_15to64',\n 'total_prison_adm',\n 'total_prison_pop',\n 'ucr_population',\n 'urbanicity',\n 'violent_crime',\n 'white_jail_pop',\n 'white_pop_15to64',\n 'white_prison_adm',\n 'white_prison_pop']\n\n\nv_county\n\n\nShow the code\nv_county().info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3139 entries, 0 to 3138\nData columns (total 16 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   county_id          3139 non-null   int64  \n 1   county_short_name  3139 non-null   object \n 2   county_name        3139 non-null   object \n 3   state_id           3139 non-null   int64  \n 4   state_short_name   3139 non-null   object \n 5   state_name         3139 non-null   object \n 6   division_id        3139 non-null   int64  \n 7   division_name      3139 non-null   object \n 8   region_id          3139 non-null   int64  \n 9   region_name        3139 non-null   object \n 10  capacity           3136 non-null   float64\n 11  commuting_zone     3138 non-null   float64\n 12  land_area          3138 non-null   float64\n 13  metro_area         1803 non-null   float64\n 14  num_employees      3136 non-null   float64\n 15  urbanicity         3139 non-null   object \ndtypes: float64(5), int64(4), object(7)\nmemory usage: 392.5+ KB\n\n\nv_crime\n\n\nShow the code\nv_crime().info()\n\n\nKeyError: \"['county_id', 'year'] not in index\"\n\n\nmv_population\n\n\nShow the code\nmv_population.info()"
  },
  {
    "objectID": "posts/20221107-tt_incarceration_trends.html#discarded",
    "href": "posts/20221107-tt_incarceration_trends.html#discarded",
    "title": "Incarceration Trends",
    "section": "Discarded",
    "text": "Discarded\nmv_admissions\ndef materialise_admissions() -> pd.DataFrame: def parse_variable(s): ls = s.split(’’) if ls[0] == ‘total’: return ls[1], ‘total’, ‘all’ if ls[0] in [‘male’, ‘female’]: ls.append(‘gender’) else: ls.append(‘ethnicity’) return ls[1], ls[-1], ls[0]\nselected_cols = [c for c in v_source().columns\n                 if 'adm' in c and 'dcrp' not in c]\nmapper = {sc: _parse_variable(sc) for sc in selected_cols}\nreturn (\n    v_source()[['county_id', 'year'] + [*mapper.keys()]]\n    .melt(id_vars=['year', 'county_id'])\n    .dropna(subset='value')\n    .assign(\n        area=lambda x: x['variable'].apply(lambda s: mapper[s][0]),\n        feature=lambda x: x['variable'].apply(lambda s: mapper[s][1]),\n        group=lambda x: x['variable'].apply(lambda s: mapper[s][2])\n    )\n    .sort_values(by=['county_id', 'year', 'area', 'feature', 'group'])\n    .reset_index(drop=True)\n    [['county_id', 'year', 'area', 'feature', 'group', 'value']]\n)\nmv_admissions = materialise_admissions()\nv_jail_pop() -> pd.DataFrame\ndef v_jail_pop() -> pd.DataFrame: return ( mv_population .query(‘area == “jail”’) .drop(columns=‘table’) )\nv_jail_vector() -> pd.DataFrame\ndef v_jail_vector() -> pd.DataFrame: selected_cols = ([‘county_id’, ‘year’] + [c for c in v_source().columns if ‘jail_from_’ in c]) return ( v_source()[selected_cols] .dropna(how=‘all’, subset=selected_cols[2:]) .reset_index(drop=True) .rename(columns={c: c.replace(‘jail_from_’, ’’) for c in selected_cols}) )"
  },
  {
    "objectID": "posts/20221108-m248_ztests.html",
    "href": "posts/20221108-m248_ztests.html",
    "title": "Z-Tests",
    "section": "",
    "text": "How to perform a one-sample and two-sample \\(z-\\)tests of population means, and a \\(z-\\)test of a population proportion using scipy and statsmodels.\nThese topics were covered in M248, Units 8 and 9.\n\nimport pandas as pd\nfrom scipy import stats as st\nfrom statsmodels.stats import weightstats as ws\nfrom statsmodels.stats import proportion as prop\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n\n%load_ext watermark\n%watermark -iv\n\nseaborn    : 0.12.1\nstatsmodels: 0.13.2\nmatplotlib : 3.6.1\nscipy      : 1.9.3\npandas     : 1.5.1\n\n\n\n\n%precision 4\nsns.set_theme()"
  },
  {
    "objectID": "posts/20221108-m248_ztests.html#test-of-population-means",
    "href": "posts/20221108-m248_ztests.html#test-of-population-means",
    "title": "Z-Tests",
    "section": "Test of population means",
    "text": "Test of population means\nData on the mean pass rate across all UK test centres during the period from April 2014 to March 2015 was obtained and analysed using an approximate normal model. (Data were taken from the Open University, who did not provide the primary source.)\nLoad the data.\n\npass_rates = pd.read_csv('https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/m248/pass_rates.csv')  # noqa\npass_rates.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 316 entries, 0 to 315\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   centre  316 non-null    object \n 1   female  316 non-null    float64\n 2   male    316 non-null    float64\n 3   total   316 non-null    float64\ndtypes: float64(3), object(1)\nmemory usage: 10.0+ KB\n\n\n\nOne-sample \\(z-\\)test\nIn the year 2013/14, the mean pass rate for all learner drivers was 47.1%. Was the mean total pass rate in 2014/15 equal to that in 2013/14?\nThis is a test of the hypotheses,\n\\[\nH_{0}: \\mu_{2014} = 47.1\\%; \\hspace{2mm} H_{1}: \\mu_{2014} \\ne 47.1\\%.\n\\]\nInititialise an instance of DescrStatsW.\n\nd = ws.DescrStatsW(pass_rates['total'])\n\nReturn a 95% interval estimate of the mean total pass rate.\n\n# lcb, ucb\nd.zconfint_mean()\n\n(48.8403, 50.4204)\n\n\nCheck the normality of the data using a normal probability plot.\n\nf, ax = plt.subplots()\nr = st.probplot(x=d.data, plot=ax)\n\n\n\n\nPerform a one-sample \\(z\\)-test.\n\n# zstat, pval\nd.ztest_mean(value=47.1)\n\n(6.2775, 0.0000)\n\n\n\n\nTwo-sample \\(z-\\)test\nWas the mean pass rate of females equal to that of males?\nThis is a test of the hypotheses,\n\\[\nH_{0}: \\mu_{f} = \\mu_{m};\n\\hspace{3mm} H_{1}: \\mu_{f} \\ne \\mu_{m}.\n\\]\nInitialise two instances of DescrStatsW, one for each sample, and an instance of CompareMeans.\n\ndf = ws.DescrStatsW(pass_rates['female'])\ndm = ws.DescrStatsW(pass_rates['male'])\ncm = ws.CompareMeans(df, dm)\n\nReturn an interval estimate of the difference between the two pass rates.\n\n# lcb, ucb\ncm.zconfint_diff()\n\n(-8.2503, -5.9294)\n\n\nCheck the normality of both data.\n\nf, axs = plt.subplots(1, 2, figsize=(8, 6), sharey=True)\nf.suptitle('Probability Plots', fontsize=16)\n# plot sample 1\nst.probplot(x=df.data, plot=axs[0])\naxs[0].set_title('variable=female')\n# plot sample 2\nst.probplot(x=dm.data, plot=axs[1])\naxs[1].set_title('variable=male')\n# plot the graphs\nplt.show()\n\n\n\n\nPerform a two-sample \\(z\\)-test.\n\n# zstat, pval\ncm.ztest_ind()\n\n(-11.9746, 0.0000)"
  },
  {
    "objectID": "posts/20221108-m248_ztests.html#test-of-a-proportion",
    "href": "posts/20221108-m248_ztests.html#test-of-a-proportion",
    "title": "Z-Tests",
    "section": "Test of a proportion",
    "text": "Test of a proportion\n\nNewborn babies are more likely to be male than female. A random sample found 13,173 males were born among 25,468 newborn children.\nIs this sample evidence that the birth of males is more common than the birth of females in the entire population?\nTest of Proportion (Statistics Online, Pennsylvania State University)\n\nThis is a test of the hypothesis,\n\\[\nH_{0}: p_{m} = 0.5; \\hspace{3mm} p_{m} > 0.5,\n\\]\nwhere \\(p_{m}\\) is the proportion of male births.\nDeclare and initialise x, n, where x is the number of male births and n is the sample size.\n\nx, n = 13_173, 25_468\nx/n\n\n0.5172\n\n\nReturn a 95% interval estimate of the proportion of male births.\n\n# lcb, ucb\nprop.proportion_confint(x, n)\n\n(0.5111, 0.5234)\n\n\nPerform a one-sided z-test of a proportion.\n\n# zstat, pval\nprop.proportions_ztest(x, n, value=0.5, alternative='larger')\n\n(5.5050, 0.0000)"
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html",
    "href": "posts/20221112-jl_advent_2015.html",
    "title": "Advent of Code 2015",
    "section": "",
    "text": "These are my solutions to the Advent of Code 2015 in Julia."
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html#history",
    "href": "posts/20221112-jl_advent_2015.html#history",
    "title": "Advent of Code 2015",
    "section": "History",
    "text": "History\n\n(2022-11-12) Initialised the notebook"
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html#setup-evironment",
    "href": "posts/20221112-jl_advent_2015.html#setup-evironment",
    "title": "Advent of Code 2015",
    "section": "Setup Evironment",
    "text": "Setup Evironment\n\nusing Pkg; Pkg.activate(\"..\\\\venvs\\\\aoc_jl\");\n\n  Activating project at `D:\\GitHub\\laughingrook\\venvs\\aoc_jl`"
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html#dependencies",
    "href": "posts/20221112-jl_advent_2015.html#dependencies",
    "title": "Advent of Code 2015",
    "section": "Dependencies",
    "text": "Dependencies"
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html#constants",
    "href": "posts/20221112-jl_advent_2015.html#constants",
    "title": "Advent of Code 2015",
    "section": "Constants",
    "text": "Constants\n\nADVENT = \"https://raw.githubusercontent.com/ljk233/laughingrook-datasets/main/aoc/\";"
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html#functions",
    "href": "posts/20221112-jl_advent_2015.html#functions",
    "title": "Advent of Code 2015",
    "section": "Functions",
    "text": "Functions\n\nhead(a) = a[1:3]\n\nhead (generic function with 1 method)"
  },
  {
    "objectID": "posts/20221112-jl_advent_2015.html#puzzles",
    "href": "posts/20221112-jl_advent_2015.html#puzzles",
    "title": "Advent of Code 2015",
    "section": "Puzzles",
    "text": "Puzzles\n\nDay 1\n--- Not Quite Lisp ---\n\n\nLoad the input\ntinput1 = String[\"(())\", \"()()\", \"(((\", \"(()(()(\", \"))(((((\",\n                 \"())\", \"))(\", \")))\", \")())())\"];\ninput1 = read(open(download(ADVENT * \"2015/2015_1.txt\")), String);\n\n\nPrepare the input.\n\nfloor_direction(d) = d == '(' ? 1 : -1\nfloor_directions = [floor_direction(d) for d ∈ collect(input1)]\nhead(floor_directions)\n\n3-element Vector{Int64}:\n  1\n -1\n  1\n\n\n\nPart 1\nTo what floor do the instructions take Santa?\nSolution =\n\nsum(floor_directions)\n\n138\n\n\n\n\nPart 2\nWhat is the position of the character that causes Santa to first enter the basement?\n\nfunction search_basement(fd, s, i)\n    if i > length(fd)\n        return Inf\n    elseif s + fd[i] == -1\n        return i\n    else\n        return search_basement(fd, s + fd[i], i+1)\n    end\nend\n\nsearch_basement (generic function with 1 method)\n\n\nSolution =\n\nsearch_basement(floor_directions, 0, 1)\n\n1771\n\n\n\n\n\nDay 2\n--- I Was Told There Would Be No Math(s) ---\n\n\nLoad the input\ntinput2 = String[\"2x3x4\", \"1x1x10\"];\ninput2 = readlines(open(download(ADVENT * \"2015/2015_2.txt\")));\n\n\nPrepare the input.\n\nppdims = map(input2) do s\n    parse.(Int, split(s, 'x'))\nend\nhead(ppdims)\n\n3-element Vector{Vector{Int64}}:\n [4, 23, 21]\n [22, 29, 19]\n [11, 4, 11]\n\n\n\nPart 1\nAll numbers in the elves’ list are in feet. How many total square feet of wrapping paper should they order?\n\nfunction paper_needed(dims)\n    le, w, h = dims\n    planes = [le * w, w * h, h * le]\n    return minimum(planes) + 2 * sum(planes)\nend\n\npaper_needed (generic function with 1 method)\n\n\nSolution =\n\nsum(paper_needed(pdims) for pdims in ppdims)\n\n1598415\n\n\n\n\nPart 2\nHow many total feet of ribbon should they order?\n\nfunction ribbon_needed(dims)\n    bow = prod(dims)\n    ribbon = 2 * sum(sort(dims)[1:2])\n    return bow + ribbon\nend\n\nribbon_needed (generic function with 1 method)\n\n\nSolution =\n\nsum(ribbon_needed(pdims) for pdims in ppdims)\n\n3812909\n\n\n\n\n\nDay 3\n--- Perfectly Spherical Houses in a Vacuum ---\n\n\nLoad the input\ntinput3 = \"^v^v^v^v^v\";\ninput3 = read(open(download(ADVENT * \"2015/2015_3.txt\")), String);\n\n\nPrepare the input.\n\ndelivery_deltas = map(collect(input3)) do d\n    if d == '>'\n        delta = [1, 0]\n    elseif d == '<'\n        delta = [-1, 0] \n    elseif d == '^'\n        delta = [0, 1] \n    else\n        delta = [0, -1]\n    end\n    delta\nend\nhead(delivery_deltas)\n\n3-element Vector{Vector{Int64}}:\n [0, 1]\n [0, 1]\n [-1, 0]\n\n\n\nPart 1\nHowever, the elf back at the north pole has had a little too much eggnog, and so his directions are a little off, and Santa ends up visiting some houses more than once. How many houses receive at least one present?\n\nfunction deliver_presents(deltas)\n    houses, pos = Set(), [0, 0]\n    push!(houses, pos)\n    for delta in deltas\n        pos += delta\n        push!(houses, pos)\n    end\n    return houses\nend\n\ndeliver_presents (generic function with 1 method)\n\n\nSolution =\n\nlength(deliver_presents(delivery_deltas))\n\n2565\n\n\n\n\nPart 2\nHow many houses if you include robo-santa?\nSolution =\n\nsanta_deliveries = deliver_presents(delivery_deltas[1:2:end])\nrob_santa_deliveries = deliver_presents(delivery_deltas[2:2:end])\nlength(union(santa_deliveries, rob_santa_deliveries))\n\n2639"
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/idna-3.4.dist-info/LICENSE.html",
    "href": "venvs/advent/Lib/site-packages/idna-3.4.dist-info/LICENSE.html",
    "title": "LaughingRook",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2021, Kim Davies All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/ipykernel-6.16.0.dist-info/licenses/COPYING.html",
    "href": "venvs/advent/Lib/site-packages/ipykernel-6.16.0.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/jupyter_client-7.4.1.dist-info/licenses/COPYING.html",
    "href": "venvs/advent/Lib/site-packages/jupyter_client-7.4.1.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "href": "venvs/advent/Lib/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "venvs/advent/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "LaughingRook",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "venvs/advent/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "LaughingRook",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "venvs/advent/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "LaughingRook",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "href": "venvs/advent/Lib/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/soupsieve-2.3.2.post1.dist-info/license_files/LICENSE.html",
    "href": "venvs/advent/Lib/site-packages/soupsieve-2.3.2.post1.dist-info/license_files/LICENSE.html",
    "title": "LaughingRook",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2022 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "venvs/advent/Lib/site-packages/traitlets-5.4.0.dist-info/licenses/COPYING.html",
    "href": "venvs/advent/Lib/site-packages/traitlets-5.4.0.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/idna-3.4.dist-info/LICENSE.html",
    "href": "venvs/lr_datavis/Lib/site-packages/idna-3.4.dist-info/LICENSE.html",
    "title": "LaughingRook",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2021, Kim Davies All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/ipykernel-6.16.1.dist-info/licenses/COPYING.html",
    "href": "venvs/lr_datavis/Lib/site-packages/ipykernel-6.16.1.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/jupyter_client-7.4.3.dist-info/licenses/COPYING.html",
    "href": "venvs/lr_datavis/Lib/site-packages/jupyter_client-7.4.3.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/jupyter_core-4.11.2.dist-info/licenses/COPYING.html",
    "href": "venvs/lr_datavis/Lib/site-packages/jupyter_core-4.11.2.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "venvs/lr_datavis/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "LaughingRook",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "venvs/lr_datavis/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "LaughingRook",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "venvs/lr_datavis/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "LaughingRook",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/nbformat-5.7.0.dist-info/licenses/COPYING.html",
    "href": "venvs/lr_datavis/Lib/site-packages/nbformat-5.7.0.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "href": "venvs/lr_datavis/Lib/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/seaborn-0.12.1.dist-info/LICENSE.html",
    "href": "venvs/lr_datavis/Lib/site-packages/seaborn-0.12.1.dist-info/LICENSE.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Copyright (c) 2012-2021, Michael L. Waskom All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "href": "venvs/lr_datavis/Lib/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Matthew Rocklin @mrocklin\nJohn Jacobsen @eigenhombre\nErik Welch @eriknw\nJohn Crichton @jcrichton\nHan Semaj @microamp\nGraeme Coupar @obmarg\nLeonid Shvechikov @shvechikov\nLars Buitinck @larsmans\nJosé Ricardo @josericardo\nTom Prince @tomprince\nBart van Merriënboer @bartvm\nNikolaos-Digenis Karagiannis @digenis\nAntonio Lima @themiurgo\nJoe Jevnik @llllllllll\nRory Kirchner @roryk\nSteven Cutting @steven_cutting\nAric Coady @coady"
  },
  {
    "objectID": "venvs/lr_datavis/Lib/site-packages/traitlets-5.5.0.dist-info/licenses/COPYING.html",
    "href": "venvs/lr_datavis/Lib/site-packages/traitlets-5.5.0.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/idna-3.4.dist-info/LICENSE.html",
    "href": "venvs/lr_stats/Lib/site-packages/idna-3.4.dist-info/LICENSE.html",
    "title": "LaughingRook",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2021, Kim Davies All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/ipykernel-6.15.1.dist-info/license_files/COPYING.html",
    "href": "venvs/lr_stats/Lib/site-packages/ipykernel-6.15.1.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/jupyter_client-7.3.4.dist-info/license_files/COPYING.html",
    "href": "venvs/lr_stats/Lib/site-packages/jupyter_client-7.3.4.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "href": "venvs/lr_stats/Lib/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "venvs/lr_stats/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "LaughingRook",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "venvs/lr_stats/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "LaughingRook",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "venvs/lr_stats/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "LaughingRook",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/pmdarima-2.0.1.dist-info/AUTHORS.html",
    "href": "venvs/lr_stats/Lib/site-packages/pmdarima-2.0.1.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "The following people have been core contributors to pmdarima’s development:\n\nTaylor Smith\nGary Foreman\nCharles Drotar\nSteven Hoelscher\nAaron Smith\nKrishna Sunkara\nChristopher Siewert\n\nPlease do not email the authors directly with questions or issues. Rather, use the issues page. Furthermore, issues or emails specifically related to assistance in learning time series analysis should be saved for Stack Overflow."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/pyzmq-23.2.1.dist-info/AUTHORS.html",
    "href": "venvs/lr_stats/Lib/site-packages/pyzmq-23.2.1.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/seaborn-0.12.1.dist-info/LICENSE.html",
    "href": "venvs/lr_stats/Lib/site-packages/seaborn-0.12.1.dist-info/LICENSE.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Copyright (c) 2012-2021, Michael L. Waskom All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "href": "venvs/lr_stats/Lib/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Matthew Rocklin @mrocklin\nJohn Jacobsen @eigenhombre\nErik Welch @eriknw\nJohn Crichton @jcrichton\nHan Semaj @microamp\nGraeme Coupar @obmarg\nLeonid Shvechikov @shvechikov\nLars Buitinck @larsmans\nJosé Ricardo @josericardo\nTom Prince @tomprince\nBart van Merriënboer @bartvm\nNikolaos-Digenis Karagiannis @digenis\nAntonio Lima @themiurgo\nJoe Jevnik @llllllllll\nRory Kirchner @roryk\nSteven Cutting @steven_cutting\nAric Coady @coady"
  },
  {
    "objectID": "venvs/lr_stats/Lib/site-packages/traitlets-5.3.0.dist-info/license_files/COPYING.html",
    "href": "venvs/lr_stats/Lib/site-packages/traitlets-5.3.0.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/ipykernel-6.15.1.dist-info/license_files/COPYING.html",
    "href": "venvs/pymc4/Lib/site-packages/ipykernel-6.15.1.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/jupyter_client-7.3.5.dist-info/licenses/COPYING.html",
    "href": "venvs/pymc4/Lib/site-packages/jupyter_client-7.3.5.dist-info/licenses/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "href": "venvs/pymc4/Lib/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "venvs/pymc4/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "LaughingRook",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "venvs/pymc4/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "LaughingRook",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figues embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "venvs/pymc4/Lib/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "LaughingRook",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/pyzmq-23.2.1.dist-info/AUTHORS.html",
    "href": "venvs/pymc4/Lib/site-packages/pyzmq-23.2.1.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "href": "venvs/pymc4/Lib/site-packages/toolz-0.12.0.dist-info/AUTHORS.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Matthew Rocklin @mrocklin\nJohn Jacobsen @eigenhombre\nErik Welch @eriknw\nJohn Crichton @jcrichton\nHan Semaj @microamp\nGraeme Coupar @obmarg\nLeonid Shvechikov @shvechikov\nLars Buitinck @larsmans\nJosé Ricardo @josericardo\nTom Prince @tomprince\nBart van Merriënboer @bartvm\nNikolaos-Digenis Karagiannis @digenis\nAntonio Lima @themiurgo\nJoe Jevnik @llllllllll\nRory Kirchner @roryk\nSteven Cutting @steven_cutting\nAric Coady @coady"
  },
  {
    "objectID": "venvs/pymc4/Lib/site-packages/traitlets-5.3.0.dist-info/license_files/COPYING.html",
    "href": "venvs/pymc4/Lib/site-packages/traitlets-5.3.0.dist-info/license_files/COPYING.html",
    "title": "LaughingRook",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  }
]